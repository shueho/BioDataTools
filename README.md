[Chinese](README-zh.md) | [English](README.md)              

# BioDataTools

This is a set of bioinformatics scripts that integrates omics and ecological genetic analyses, supports various data processing tools, and accommodates a wide range of research needs.
   

## Script Tools Directory

This README document provides script files under each module and their brief functional descriptions, as well as concise overviews of certain analysis workflows.  The document is available in both Chinese and English versions, and you may switch between them according to your preference.  

<table border="0" cellspacing="0" cellpadding="5">
  <tr>
    <th>Script No.</th>
    <th>Script Name</th>
    <th>Brief Function Description</th>
  </tr>
  <tr><th colspan="3" style="text-align:center; font-weight:bold;">Metagenome: Metagenomic Analysis Module</th></tr>
  <tr><td>1.01</td><td>QuastAssemblerSummary</td><td>Summary of Quast software evaluation results</td></tr>
  <tr><td>1.02</td><td>FastaSeqsRenamerUniqueContinuous</td><td>Re-number each sequence in Fasta format</td></tr>
  <tr><td>1.03</td><td>MPAtoMatrix</td><td>Merge MPA files generated by Kraken1/2 or Bracken</td></tr>
  <tr><td>1.04</td><td>TaxLevelMatrixSplitter</td><td>Split the species abundance table according to taxonomic ranks</td></tr>
  <tr><th colspan="3" style="text-align:center; font-weight:bold;">Genetics: Genome Analysis Module</th></tr>
  <tr><td>2.01</td><td>GIGenBankDownloader</td><td>Batch download Fasta files by GI number</td></tr>
  <tr><td>2.02</td><td>GBRenameByX</td><td>Batch rename GB files based on specific information</td></tr>
  <tr><td>2.03</td><td>GBtoFastaWithDescriptions</td><td>Batch convert GB files to Fasta files</td></tr>
  <tr><td>2.04</td><td>CombineTwoSequences</td><td>Merge two sequences</td></tr>
  <tr><td>2.05</td><td>FastaToHaplotypes</td><td>Convert sample sequences into haplotype sequences</td></tr>
  <tr><td>2.06</td><td>CustomFastaExtractor</td><td>Extract a subset of sequences from a Fasta file using regular expressions</td></tr>
  <tr><td>2.07</td><td>ProteinPropertyFromExpasy</td><td>Batch retrieval of protein physicochemical properties</td></tr>
  <tr><td>2.08</td><td>FeaturesBaseComponents</td><td>Summary statistics of organellar genome features</td></tr>
  <tr><td>2.09</td><td>ExAndRename</td><td>Extract subsequences from a Fasta file and rename them</td></tr>
  <tr><td>2.10</td><td>BatchFastaToPam</td><td>Batch convert Fasta files to PAML format files</td></tr>
  <tr><td>2.11</td><td>ReassignSequence</td><td>Reassign sequences to their respective Fasta file</td></tr>
  <tr><td>2.12</td><td>BatchAlignedProteinToDNA</td><td>Convert a protein alignment file to a codon alignment file</td></tr>
  <tr><td>2.13</td><td>Extract4DTv</td><td>Extract 4DTv sites</td></tr>
  <tr><td>2.14</td><td>MergeSequences</td><td>Merge sequences (advanced)</td></tr>
  <tr><td>2.15</td><td>BatchGenerationCodeML_CTL</td><td>Batch generate configuration files for CodeML</td></tr>
  <tr><td>2.16</td><td>ParsingCodeMLResults</td><td>Batch parse CodeML results</td></tr>
  <tr><td>2.17</td><td>SplitAXT</td><td>Split AXT files</td></tr>
  <tr><td>2.18</td><td>BaseSiteInformation</td><td>Obtain the positional information of nucleotides on the genome</td></tr>
  <tr><td>2.19</td><td>MaskSeq</td><td>Genome mask</td></tr>
  <tr><td>2.20</td><td>BaseCompositionCalculation</td><td>Statistical analysis of base counts by codon position</td></tr>
  <tr><td>2.21</td><td>GFFSimplifier</td><td>Simplify GFF file</td></tr>
  <tr><td>2.22</td><td>BaseSiteFeatureFinder</td><td>Retrieve features near a site (candidate gene screening within a specified distance)</td></tr>
  <tr><td>2.23</td><td>IntervalFeatureFinder</td><td>Retrieve features within a specified region (candidate gene screening within a defined interval)</td></tr>
  <tr><td>2.24</td><td>ExtractFastaWithGene</td><td>Extract all transcripts/proteins/cDNA, etc. corresponding to a gene</td></tr>
  <tr><td>2.25</td><td>CorrespondingNucleotideProteinFasta</td><td>Associate transcript sequences with protein sequences</td></tr>
  <tr><td>2.26</td><td>BatchModificationSequence</td><td>Batch replace the sequence preceding a fixed sequence with a specified sequence</td></tr>
  <tr><td>2.27</td><td>TableToMultipleFasta</td><td>Split a Fasta file according to the rows in a table</td></tr>
  <tr><td>2.28</td><td>MultipleFastaToTable</td><td>Merge multiple Fasta files into a single table</td></tr>
  <tr><td>2.29</td><td>AlignConsistencyChecker</td><td>Simple visualization of sequence alignment results</td></tr>
  <tr><td>2.30</td><td>MergeMultipleFasta</td><td>Merge multiple Fasta files and remove redundant sequences</td></tr>
  <tr><td>2.31</td><td>MitosToGFF</td><td>Convert Mitos annotation results to GFF file</td></tr>
  <tr><td>2.32</td><td>MitosToFasta</td><td>Convert Mitos annotation results to Fasta file</td></tr> 
  <tr><td>2.33</td><td>SsToFold</td><td>Convert secondary structure files (.ss) generated by tRNAscan-SE into a format supported by RNAplot</td></tr> 
  <tr><td>2.34</td><td>RSCUPlot</td><td>Analyze the codon usage bias of protein-coding genes and generate a bar chart of Relative Synonymous Codon Usage (RSCU)</td></tr> 
  <tr><td>2.35</td><td>splitGB</td><td>Split multi-sequence GeneBank files</td></tr>   
  <tr><th colspan="3" style="text-align:center; font-weight:bold;">Gadget: General Utilities Module</th></tr>
  <tr><td>3.01</td><td>MergeTable</td><td>Merge extremely large tables</td></tr>
  <tr><td>3.02</td><td>VLookup</td><td>VLOOKUP function (advanced)</td></tr>
  <tr><td>3.03</td><td>SumByGroup</td><td>Grouped summation (advanced)</td></tr>
  <tr><td>3.04</td><td>CountByGroup</td><td>Grouped counting (advanced)</td></tr>
  <tr><td>3.05</td><td>FastaSplitter</td><td>Split Fasta file by specified number of sequences</td></tr>
  <tr><td>3.06</td><td>KeggAnnotationParser</td><td>Parse KEGG annotation file</td></tr>
  <tr><td>3.07</td><td>KEGGPathwayCounter</td><td>KEGG pathway count statistics</td></tr>
  <tr><td>3.08</td><td>GOoboAnnotationExtractor</td><td>Parse GO annotation obo file</td></tr>
  <tr><td>3.09</td><td>GOTableConverter</td><td>Convert GO annotation table</td></tr>
  <tr><td>3.10</td><td>AddGOAnnotations</td><td>Add GO annotation descriptions and category information</td></tr>
  <tr><td>3.11</td><td>VectorTableMerger</td><td>Join table A-Bs and table B-Cs to form table A-Cs</td></tr>
  <tr><th colspan="3" style="text-align:center; font-weight:bold;">Plotscript: Plotting Tools Module</th></tr>
  <tr><td>4.01</td><td>GeneArrangementMap</td><td>Draw a genomic feature arrangement chart</td></tr>
  <tr><td>4.02</td><td>TrnaStructureBeautifier</td><td>Beautification of tRNA secondary structure diagram</td></tr>
  <tr><th colspan="3" style="text-align:center; font-weight:bold;">BioDataSpider: Biological Database Web Scraping Tools Module</th></tr>
  <tr><td>5.01</td><td>GenoSpider</td><td>Genome information web scraper</td></tr>
  <tr><td>5.02</td><td>PrideSpider</td><td>PRIDE database information web scraper</td></tr>
  <tr><th colspan="3" style="text-align:center; font-weight:bold;">Analysis Pipeline</th></tr>
  <tr><td colspan="2">Metagenomic Species Quantification Analysis Pipeline</td><td>Located after script 1.04</td></tr>
  <tr><td colspan="2">Population Genetics Analysis: Rapid Data Download Workflow</td><td>Located after script 2.03</td></tr>
  <tr><td colspan="2">Comparative Genomics - Homologous Gene Phylogenetic Tree Construction and Selection Pressure Analysis Pipeline (I)</td><td>Located after script 2.16</td></tr>
  <tr><td colspan="2">Comparative Genomics - Homologous Gene Phylogenetic Tree Construction and Selection Pressure Analysis Pipeline (II)</td><td>Located after script 2.17</td></tr>
  <tr><td colspan="2">GO/KEGG Enrichment Analysis Pipeline without a Reference Genome</td><td>Located after script 3.10</td></tr>
</table>


## 1. Metagenome: Scripts related to metagenomic analysis
   
### 1.01 `QuastAssemblerSummary.py [DIR_PATH]`

**Function Description:** Place the script in the parent directory of the assembly evaluation results completed by quast software to obtain the assembly evaluation information summary table.  

- **DIR_PATH: ** Path to the Quast results folder, containing the `transposed_report.tsv` file for each sample. 

**Generated File:**

- `sumary.tsv`(Table file, where each column represents a sample and each row corresponds to an assembled dataset).  

**Example:**

For example, the `example/quast` folder contains the assembly evaluation results for each sample obtained using the Quast software. Its file structure is as follows: 
```
example/
└── quast/
    ├── sp1/
    │   └── transposed_report.tsv
    ├── sp2/
    │   └── transposed_report.tsv
    └── sp3/
        └── transposed_report.tsv
```
Execute command:  
```bash
python QuastAssemblerSummary.py example/quast
```
Output result file `summary.tsv`, content example:  
```
Sample    N50    Total Length    # Contigs    Largest Contig    GC (%)    ...
sp1       10000   5000000         100           25000       42.3      ...
sp2       12000   5500000         85            30000       41.7      ...
sp3       15000   6000000         70            40000       43.1      ...
```

### 1.02 `FastaSeqsRenamerUniqueContinuous.py [FASTA_FILE_PATH]` 

**Function Description:** Modify the name in each sequence of the specified FASTA file to make it standardized and uniform.

- **FASTA_FILE_PATH:** Original FASTA file path.

**Usage Scenario:** In omics analysis projects such as metagenomics, this script ensures the uniqueness of identifiers when merging sample assembly data by uniformly renaming sequence IDs in each FASTA file to consecutive numbers (1, 2, 3...). This standardizes sequence names for subsequent gene abundance analysis and annotation, facilitating the tracking of differentially expressed genes and alignment to original sequences.

**Notes:** This code is only suitable for scenarios where the original sequence identifiers are no longer discussed subsequently. Do not use this script after downstream analyses such as quantification or annotation! Do not confuse this with script 2.30. This script renumbers sequences (assigning different IDs regardless of sequence identity), whereas 2.30 assigns a unified ID to duplicate sequences, retaining only the last occurrence if identical IDs exist in the original files (regardless of sequence similarity).  

**Generated File:** 
- `out_<Original FASTA File Name>`(FASTA file with sequences re-numbered).     

**Example:**

For example, the `example/origin_seq.fa` file contains sequences with duplicate identifiers:  
```
>aaa
ATCGGCATATATCTTATTATATTTCCCCAAA
>abc
ATCGGCATATATCTTATTATATTTCCCCAAA
TTCCATCA
>aaa
ATCGGCATATATCTTATTATATTTCCCCAAA
>ac
ATCGGCATATATCTTATTATATTTCCCCAAA
>at
ATCGGCATATATCTTATTATATTTCCCCAAA
TTCCATCA
>aa
ATCGGCATATATCTTATTATATTTCCCCAAA
```
Execute command:  
```bash
python FastaSeqsRenamerUniqueContinuous.py example/origin_seq.fa
``` 
The output result file `out_origin_seq.fa` is the FASTA file with unique sequence identifiers: 
```
>N_0000000001 
ATCGGCATATATCTTATTATATTTCCCCAAA
>N_0000000002 
ATCGGCATATATCTTATTATATTTCCCCAAATTCCATCA
>N_0000000003 
ATCGGCATATATCTTATTATATTTCCCCAAA
>N_0000000004 
ATCGGCATATATCTTATTATATTTCCCCAAA
>N_0000000005 
ATCGGCATATATCTTATTATATTTCCCCAAATTCCATCA
>N_0000000006 
ATCGGCATATATCTTATTATATTTCCCCAAA
```  

### 1.03 `MPAtoMatrix.py  [MPA_PATH]` 

**Function Description:** Convert mpa files generated by Kraken1/2 or Bracken software into a species abundance matrix.     

- **MPA_PATH:** Path to the MPA files for all samples. 

**Notes:** This script supports processing MPA file directories output by Kraken 1, Kraken 2, or Bracken. Before running, please use the kreport2mpa.py script to convert the results into MPA format. Importantly, all MPA files must be generated based on the same nucleotide database, as the order of species abundance depends on the selected database, ensuring data consistency.  

**Generated File:** 
- `mpaMatrix.txt`(Table file, species abundance table, each column represents a sample).     

**Example:**

For example, the `example/mpa` file contains MPA files for multiple samples:  
```
example/
└── mpa/
    ├── sp1.mpa   
    ├── sp2.mpa   
    ├── sp3.mpa 
    └── sp4.mpa
```
Execute command:  
```bash
python MPAtoMatrix.py example/mpa
``` 
The output result file `mpaMatrix.txt` is the species abundance matrix, where the first column contains the annotated species taxonomic information, and the remaining columns represent the species abundance annotated for each sample:
```
#Classification	sp1	sp2	sp3	sp4
k__Eukaryota	13682	9638	9039	14460
k__Eukaryota|k__Fungi	13682	9638	9039	14460
k__Eukaryota|k__Fungi|p__Ascomycota	12398	8678	8176	12898
k__Eukaryota|k__Fungi|p__Ascomycota|c__Sordariomycetes	8893	5998	5014	8723
k__Eukaryota|k__Fungi|p__Ascomycota|c__Sordariomycetes|o__Hypocreales	4102	2580	2178	3841
k__Eukaryota|k__Fungi|p__Ascomycota|c__Sordariomycetes|o__Hypocreales|f__Ophiocordycipitaceae	1937	1338	1155	1969
...
k__Eukaryota|k__Fungi|p__Microsporidia	11	5	7	14
k__Eukaryota|k__Fungi|p__Microsporidia|f__Unikaryonidae	11	5	7	14
k__Eukaryota|k__Fungi|p__Microsporidia|f__Unikaryonidae|g__Encephalitozoon	11	5	7	14
k__Eukaryota|k__Fungi|p__Microsporidia|f__Unikaryonidae|g__Encephalitozoon|s__Encephalitozoon_intestinalis	5	1	3	3
k__Eukaryota|k__Fungi|p__Microsporidia|f__Unikaryonidae|g__Encephalitozoon|s__Encephalitozoon_romaleae	2	2	0	5
k__Eukaryota|k__Fungi|p__Microsporidia|f__Unikaryonidae|g__Encephalitozoon|s__Encephalitozoon_hellem	2	1	3	4
k__Eukaryota|k__Fungi|p__Microsporidia|f__Unikaryonidae|g__Encephalitozoon|s__Encephalitozoon_cuniculi	1	1	0	2
```  

### 1.04 `TaxLevelMatrixSplitter.py [MPA_MERGE_FILE] [SPLIT_LEVEL]` 

**Function Description:** This script extracts species abundance data for various taxonomic ranks from the species abundance table and constructs corresponding abundance matrices. 

- **MPA_MERGE_FILE:** The file path for `1.03 MPAtoMatrix.py` generated by the `mpaMatrix.txt` script. You can also modify your abundance table to match the style of the example file.
- **SPLIT_LEVEL:** To specify the taxonomic level for the output species abundance table, use the following single-letter identifiers: 'a' (all levels), 'K' (Kingdom), 'P' (Phylum), 'C' (Class), 'O' (Order), 'F' (Family), 'G' (Genus), 'S' (Species). Note that 'a' indicates outputting abundance tables for all taxonomic ranks. Both uppercase and lowercase letters are acceptable. 

**Generated File:** 
- `taxLevel_<Specified Taxonomic Rank (Uppercase)>_output.<Abundance Matrix File Name>`(One or more table files, species abundance tables). 

**Example:**

For example, the `example/mpaMatrix.txt` file contains species abundance information: 
```
#Classification	sp1	sp2	sp3	sp4
k__Eukaryota	13682	9638	9039	14460
k__Eukaryota|k__Fungi	13682	9638	9039	14460
k__Eukaryota|k__Fungi|p__Ascomycota	12398	8678	8176	12898
k__Eukaryota|k__Fungi|p__Ascomycota|c__Sordariomycetes	8893	5998	5014	8723
k__Eukaryota|k__Fungi|p__Ascomycota|c__Sordariomycetes|o__Hypocreales	4102	2580	2178	3841
k__Eukaryota|k__Fungi|p__Ascomycota|c__Sordariomycetes|o__Hypocreales|f__Ophiocordycipitaceae	1937	1338	1155	1969
...
k__Eukaryota|k__Fungi|p__Microsporidia	11	5	7	14
k__Eukaryota|k__Fungi|p__Microsporidia|f__Unikaryonidae	11	5	7	14
k__Eukaryota|k__Fungi|p__Microsporidia|f__Unikaryonidae|g__Encephalitozoon	11	5	7	14
k__Eukaryota|k__Fungi|p__Microsporidia|f__Unikaryonidae|g__Encephalitozoon|s__Encephalitozoon_intestinalis	5	1	3	3
k__Eukaryota|k__Fungi|p__Microsporidia|f__Unikaryonidae|g__Encephalitozoon|s__Encephalitozoon_romaleae	2	2	0	5
k__Eukaryota|k__Fungi|p__Microsporidia|f__Unikaryonidae|g__Encephalitozoon|s__Encephalitozoon_hellem	2	1	3	4
k__Eukaryota|k__Fungi|p__Microsporidia|f__Unikaryonidae|g__Encephalitozoon|s__Encephalitozoon_cuniculi	1	1	0	2
```  
Execute command:
```bash
# To generate abundance data for all taxonomic ranks, run:
python TaxLevelMatrixSplitter.py example/mpaMatrix.txt a
# Outputs 7 files for different taxonomic ranks: taxLevel_K/P/C/O/F/G/S_output.mpaMatrix.txt.

# To generate abundance data only for the Family taxonomic rank, run:
python TaxLevelMatrixSplitter.py example/mpaMatrix.txt f
# Only one result file is output: taxLevel_F_output.mpaMatrix.txt.
```
This will output the corresponding 1 or 7 result files: 
```
#taxLevel_K_output.mpaMatrix.txt
k	sp1	sp2	sp3	sp4
Eukaryota	13682	9638	9039	14460
Fungi	13682	9638	9039	14460

#taxLevel_P_output.mpaMatrix.txt
k	p	sp1	sp2	sp3	sp4
Fungi	Ascomycota	12398	8678	8176	12898
Fungi	Basidiomycota	1273	954	856	1548
Fungi	Microsporidia	11	5	7	14

#taxLevel_C_output.mpaMatrix.txt
k	p	c	sp1	sp2	sp3	sp4
Fungi	Ascomycota	Sordariomycetes	8893	5998	5014	8723
Fungi	Ascomycota	Leotiomycetes	36	20	25	49
Fungi	Ascomycota	Eurotiomycetes	1016	811	1542	1224
Fungi	Ascomycota	Dothideomycetes	530	410	370	616
Fungi	Ascomycota	Saccharomycetes	1409	1010	847	1650
Fungi	Ascomycota	Schizosaccharomycetes	511	427	374	635
Fungi	Basidiomycota	Ustilaginomycetes	658	436	430	679
Fungi	Basidiomycota	Malasseziomycetes	196	167	126	263
Fungi	Basidiomycota	Agaricomycetes	153	124	110	171
Fungi	Basidiomycota	Tremellomycetes	100	91	59	145
Fungi	Basidiomycota	Pucciniomycetes	164	134	130	287

...
#taxLevel_S_output.mpaMatrix.txt
k	p	c	o	f	g	s	sp1	sp2	sp3	sp4
Fungi	Ascomycota	Sordariomycetes	Hypocreales	Ophiocordycipitaceae	Purpureocillium	Purpureocillium_takamizusanense	998	692	605	1019
Fungi	Ascomycota	Sordariomycetes	Hypocreales	Ophiocordycipitaceae	Drechmeria	Drechmeria_coniospora	939	646	549	949
Fungi	Ascomycota	Sordariomycetes	Hypocreales	Nectriaceae	Fusarium	Fusarium_falciforme	390	181	140	284
...
Fungi	Microsporidia	-	-	Unikaryonidae	Encephalitozoon	Encephalitozoon_romaleae	2	2	0	5
Fungi	Microsporidia	-	-	Unikaryonidae	Encephalitozoon	Encephalitozoon_hellem	2	1	3	4
Fungi	Microsporidia	-	-	Unikaryonidae	Encephalitozoon	Encephalitozoon_cuniculi	1	1	0	2
```

> ## Metagenomic Species Quantification Analysis Pipeline     
> Species annotation analysis in metagenomic analysis can utilize Kraken2 and Bracken analysis software. `database_PATH` represents the path to the nucleotide database for the species group of interest, and `sp1` represents the sample name. First, use Kraken2 with the specified database to obtain the report file, where `sp1*` indicates the path to the paired-end sequencing results.       
> ```
> kraken2 --db database_PATH --paired sp1*  --threads 128 --use-names --report-zero-counts --report sp1.report --output sp1.output
> ```
> Subsequently, use Bracken to convert the report file into a Bracken file.
> ```
> bracken -d database_PATH -i sp1.report -r 150 -l S -t 0 -o sp1.bracken -w sp1.bracken.report
> ```
> Use kreport2mpa.py to obtain the mpa file.
> ```
> kreport2mpa.py -r sp1.bracken.report --display-header -o sp1.bracken.mpa
> ``` 
> The above process only analyzes the sp1 sample. In actual analysis, loop statements need to be written to batch-process the results of each sample. The obtained mpa files can be used with the 1.03 script to generate a species abundance matrix, and the 1.04 script to obtain abundance matrices at various taxonomic levels. Subsequently, analyses related to species abundance, such as α/β species diversity analysis and LEfSe analysis, can be performed.   
             

## 2. Genetics: Scripts for data processing in genomic and comparative genomic studies, covering batch data retrieval from NCBI, as well as batch extraction and batch conversion of data information content.            
 
### 2.01 `GIGenBankDownloader.py [GI_LIST_DIR]`

**Function Description:** Batch download GenBank files by GI number. 

- **GI_LIST_DIR:** Path to the directory containing GI numbers. The script automatically detects and reads all text files with the `_gi.txt` extension within the folder. These `_gi.txt` files contain the GI numbers of the sequences to be downloaded. 

**Usage scenario:** To batch download a large number of GenBank (gb) files, you simply need to create several "xxx_gi.txt" files and paste the corresponding list of GI numbers into each file. This design offers high flexibility, allowing results to be distinguished by the list filename. It facilitates the subsequent classification and archiving of different group files, greatly aiding common haplotype analysis tasks in population genetics.  

**Notes:** The requests library is required! If you need to download a large number of sequences, it is not recommended to use this script. It is recommended to use https://www.ncbi.nlm.nih.gov/sites/batchentrez for batch sequence download. 

**Generated File:** 
- `gb/<List Name>_<GI Number>.gb`(Multiple GENEBANK files are generated in the `gb` folder).  

**Example:**

For example, the `example/gi` folder contains the GI numbers of the sequences to be downloaded: 
```
#example/gi/Kinaisemen_gi.txt
1820426935
1820426934

#example/gi/Nomomachi_gi.txt
1820426946
1820426945
1820426944
```
Execute command:
```bash
python GIGenBankDownloader.py example/gi
``` 
Output folder `gb` containing multiple gb files prefixed with the list name. 
```
gb/
├── Kinaisemen_1820426934.gb   
├── Kinaisemen_1820426935.gb   
├── Nomomachi_1820426944.gb 
├── Nomomachi_1820426945.gb 
└── Nomomachi_1820426946.gb
```

### 2.02 `GBRenameByX.py [GB_DIR] [INFO_NAME]`

**Function Description:** Reads specific sample information (e.g., isolate information) from a GB file and renames the corresponding GB file based on this information. This is suitable for unified management and organization of large batches of GB files in population genetics analysis.  

- **GB_DIR:** Directory path where the GB files are stored. 
- **INFO_NAME:** Reference information needed to modify the GB file names. It is essential to ensure that this sample information is unique within different GB files.  

**Notes:** Be sure to use information that can distinguish all GB files! It's best to manually delete or rename the files generated from the previous run each time you execute the script. 

**Generated File:** 
- `output/<Value corresponding to the sample information (spaces replaced by underscores)>.gb` (Multiple GENEBANK files in the`output` folder). 

**Example:**

For example, the `example/gb_isolate` folder:
```
example/
└── gb_isolate/
    ├── Kinaisemen_1820426934.gb   
    ├── Kinaisemen_1820426935.gb   
    ├── Nomomachi_1820426944.gb 
    ├── Nomomachi_1820426945.gb 
    └── Nomomachi_1820426946.gb
```
And the `example/gb_orgnism` folder: 
```
example/
└── gb_organism/
    ├── Ansan_1820426827.gb   
    ├── Buan_1820426866.gb   
    └── Kinaisemen_1820426929.gb
```
contains multiple sample GB files distinguished by `isolate` & `orgnism` information, respectively. You can execute: 
```bash
# Run with naming based on isolate information:
python GBRenameByX.py example/gb_isolate isolate

# Run with naming based on organism information:
python GBRenameByX.py example/gb_organism organism
```
The corresponding results will be output to the `output` folder:   
```
#isolate
output/
├── Kinaisemen_06.gb   
├── Kinaisemen_07.gb   
├── Nomomachi_01.gb 
├── Nomomachi_02.gb 
└── Nomomachi_03.gb

#organism
output/
├── A_a.gb   
├── A_b.gb   
└── A_k.gb
```
     
### 2.03 `GBtoFastaWithDescriptions.py [GB_DIR]`
`
**Function Description:** Batch convert GB files to FASTA format. During the conversion process, the original GB file name is inserted into the description line of the FASTA sequence record (the part following ">") to facilitate tracking of the source file information. This is particularly important for efficiently processing large numbers of GB files, especially when conducting tasks such as population genetics analysis.  

- **GB_DIR:** Directory path where the GB files are stored.  

**Generated File:** 
- `output/<Original GB file name>.fas`(Multiple FASTA files).  

**Example:**

For example, to convert GB files in the  `example/gb_isolate` folder to FASTA files: 
```
example/
└── gb_isolate/
    ├── Kinaisemen_1820426934.gb   
    ├── Kinaisemen_1820426935.gb   
    ├── Nomomachi_1820426944.gb 
    ├── Nomomachi_1820426945.gb 
    └── Nomomachi_1820426946.gb
```
Execute command:
```bash
python GBtoFastaWithDescriptions.py example/gb_isolate
``` 
The corresponding results will be output to the `output` folder:
```
output/
├── Kinaisemen_1820426934.fas   
├── Kinaisemen_1820426935.fas   
├── Nomomachi_1820426944.fas 
├── Nomomachi_1820426945.fas 
└── Nomomachi_1820426946.fas
```

> ## Population Genetics Analysis: Rapid Data Download Workflow          
> For example, to download specific `cox1` genes from multiple populations from NCBI, you can first create a folder and list the GI numbers of the `cox1` gene for different individuals within each population in separate xxx_gi.txt files (these can be directly exported from NCBI). Then, run script 2.01 to download the corresponding GB files. Next, run script 2.02 to rename the downloaded GB files based on the 'isolate' or other tags. Finally, execute script 2.03 to generate the final FASTA format sequence files named after the tag values.   

### 2.04 `CombineTwoSequences.py [FASTA_FILE_1] [FASTA_FILE_2]`

**Function Description:** A basic version for merging sequences, an advanced version of this script (script 2.14) will be provided subsequently.  

- **FASTA_FILE_1:** First sequence.
- **FASTA_FILE_2:** Second sequence.

**Usage scenario:** Assuming you have 16S and COI sequences from samples A, B, and C, for a certain purpose, you want to combine 16S and COI sequences from different samples. You can use this script.  

**Multiple calls:** If you want to merge multiple sequences, you can call this script repeatedly.

**Notes:** Be sure to use this script on aligned sequence files!  

**Generated File:** 
- `merge.fas`(Merged FASTA file).  

**Example:**

For example, the `example/fasta_merge` directory contains the sequences `16s.fasta` and `co1.fasta`that need to be merged: 
```
#example/fasta_merge/16s.fasta
>AN012
-------------CGCTCTTTGAAATACAAATATAGAGAGTCGTGCCTGCCCAGTGATTT...
>AN015
-------------CGCTCTTTGAAATACAAATATAGAGAGTCGTGCCTGCCCAGTGATTT...

#example/fasta_merge/co1.fasta
>AN012
--TACTTTATATATTTTGTTTGGGATTTGGTCTGGATTGGTTGGAACAGCTTTAAGACTA...
>AN015
--TACTTTATATATTTTGTTTGGGATTTGGTCTGGATTGGTTGGAACAGCTTTAAGACTA...
```
Execute command:
```bash
python CombineTwoSequences.py example/fasta_merge/16s.fasta example/fasta_merge/co1.fasta
``` 
The output result file `merge.fas` is the merged sequence of 16s+co1:  
```
>AN012
-------------CGCTCTTTGAAATACAAATATAGAGAGTCGTGCCTGCCCAGTGATTT...
--TACTTTATATATTTTGTTTGGGATTTGGTCTGGATTGGTTGGAACAGCTTTAAGACTA...
>AN015
-------------CGCTCTTTGAAATACAAATATAGAGAGTCGTGCCTGCCCAGTGATTT...
--TACTTTATATATTTTGTTTGGGATTTGGTCTGGATTGGTTGGAACAGCTTTAAGACTA...
```

### 2.05 `FastaToHaplotypes.py -p [FASTA_FILE_NAME] -l [LIST_NAME]`

**Function Description:** Classify multiple sample sequences in a FASTA file according to haplotypes.

- **FASTA_FILE_NAME: ** Sample sequence file name (refer to example/sample.fas).
- **LIST_NAME: ** Table of haplotypes corresponding to samples (refer to example/hap.list).

**Notes:** Before use, two files need to be obtained: one is a table exported from DnaSP corresponding haplotypes to samples (which might need manual creation). The other is a FASTA file containing all species sequences.  

**Usage scenario:** For example, for sequence data containing five samples (a, b, c, d, e), where the sequences of samples a, b, and c are identical, and the sequences of samples d and e are also identical, this implies we have two unique haplotypes. Using this code, samples with identical sequences can be merged and classified into their respective haplotypes, which is beneficial for subsequent phylogenetic analysis focusing on different haplotype sequences. Refer to the example files and example code!!!        

**Generated File:** 
- `out_hap.fasta`(FASTA file composed of haplotypes).

**Example:**

For example, the `example/sample.fas` file is the sequence file for each sample:  
```
>a001
ATCGGCTA
>a002
ATCGGCTA
>b001
AT-GCCTA
>b002
AT-GCCTA
>b003
AT-GCCTA
>c001
--CGGCTA
```
The `example/hap.list`  file is a table corresponding haplotypes to samples:  
```
[Hap_1:  2    a001 a002]
[Hap_2:  3    b001 b002 b003]
[Hap_3:  1    c001]
```
Execute command:
```bash
python FastaToHaplotypes.py -p example/sample.fas -l example/hap.list
``` 
The output result file `out_hap.fasta`  is the haplotype sequence file:  
```
>H1
ATCGGCTA
>H2
AT-GCCTA
>H3
--CGGCTA
```

### 2.06 `CustomFastaExtractor.py [FASTA_FILE] [LIST_FILE] [Regular_expressions (Optional)]`

**Function Description:** Based on a provided ID list, this script can extract corresponding sequences from a single multi-sequence FASTA file to generate a subset FASTA file. By default, the system identifies the text following the ">" symbol up to the first space as the ID, matching it against the entries in the list. For complex scenarios, custom regular expressions are supported to achieve precise ID matching, ensuring flexible and efficient target sequence screening.

- **FASTA_FILE: ** A sequence file in Fasta format, which includes all sequences, such as the pep or CDS sequences of a whole genome.  
- **LIST_FILE: ** The list should contain the sequence IDs or names you wish to extract. This information can be the entire description field immediately following the ">" symbol for each sequence in the FASTA_FILE, or just a part of that description field.  
- **Regular_expressions: ** Optional parameter: If the names in your list differ from the sequence names in the FASTA file, you can specify a regular expression to extract the sequences. If left blank, the default is: "\_(.*?)". This means the content before the first space after ">" will be used as the ID name.

**Usage scenario:** During collinearity analysis or homologous gene clustering, it is common to encounter pep files downloaded from NCBI containing a large amount of redundant data. To optimize this process, one can optionally download a non-redundant protein sequence database covering only chromosome-encoded sequences. This script is specifically designed to extract the required segments from the large pep file based on user-provided sequence names. Furthermore, it supports extracting the corresponding coding sequences (CDS). Considering potential differences between protein sequence IDs and CDS IDs, introducing custom matching rules via regular expressions is particularly important. For further process simplification, it is recommended to use the upgraded code version 2.09, which can also effectively perform such extraction tasks.  

**Notes:** Cannot be used to extract multiple transcripts of a single gene! This code does not support extracting different transcript/protein sequences of the same gene name! It can only extract sequences with unique gene names! If you have this requirement, please refer to script 2.24!       

**Generated File:** 
- `out_match_seq.fasta`(FASTA file).

**Example:**

For example, `example/text1.fa` and`example/text2.fa`are complete FASTA files:
```
#example/text1.fa
>KAF7112153.1 hypothetical protein RHSIM_RhsimUnG0257300 [Rhododendron simsii]
MASVKNRVRNKLFKCFRPAAIDDDPIKPDATDGPGNSVFTSISGKGKSGKISNLLSGEKGKVYSEGGDAGGDRSNKERSH...
>KAF7112159.1 hypothetical protein RHSIM_RhsimUnG0256100 [Rhododendron simsii]
MASNTQSSFEDFLPIMAHKLGGEALIGELCNGFRLLMDGDKGVITFDSLKKNAAVLGLQELTDGDLRSMLREGDFDGDGA...
...
>KAF7152831.1 hypothetical protein RHSIM_Rhsim01G0241100 [Rhododendron simsii]
MASTHITPQTNFSSFSKAQFMASSATSFTDLLAGDYPSSSAVSRGLSDRIAERTGSGVPKFKSIPPPSIPTSPHAVSPSF...

#example/text2.fa
>Rhsim01G0033600
ATCGGTAC
>Rhsim01G0241100
ATACCCCCVHHHHH
>abc
ADFAAFAFAF
>def
DAFAFAFAGFAG
```
The list `example/list1.txt` and `example/list1.txt`contain the names of the sequences to be extracted: 
```
#example/list1.txt
KAF7112159.1
KAF7153261.1

#example/list2.txt
Rhsim01G0033600
Rhsim01G0241100
```

Execute command:
```bash
# If the sequence names you need to extract are the content before the first space, especially for FASTA files downloaded directly from NCBI, you can run directly: 
python CustomFastaExtractor.py example/text1.fa example/list1.txt

# Commonly used! If the sequence names you need to extract are all the content after >, you can run directly: 
python CustomFastaExtractor.py example/text2.fa example/list2.txt "\>(.*)"

# If using regular expressions for extraction: 
python CustomFastaExtractor.py example/text1.fa example/list2.txt "\_(.*?) "
```
The corresponding subset sequence files will be output:
```
#python CustomFastaExtractor.py example/text1.fa example/list1.txt
>KAF7112159.1 hypothetical protein RHSIM_RhsimUnG0256100 [Rhododendron simsii]
MASNTQSSFEDFLPIMAHKLGGEALIGELCNGFRLLMDGDKGVITFDSLKKNAAVLGLQELTDGDLRSMLREGDFDGDGA...
>KAF7153261.1 hypothetical protein RHSIM_Rhsim01G0033600 [Rhododendron simsii]
MDQVGKSHQQALVSVITEAAQSQLKNEVTESPQCPTSSSELSPTSVTQSISSGPTNKKLSLVANTNSACMPEVVRQNSSN

#python CustomFastaExtractor.py example/text2.fa example/list2.txt "\>(.*)"
>Rhsim01G0033600
ATCGGTAC
>Rhsim01G0241100
ATACCCCCVHHHHH

#python CustomFastaExtractor.py example/text1.fa example/list2.txt "\_(.*?) "
>KAF7153261.1 hypothetical protein RHSIM_Rhsim01G0033600 [Rhododendron simsii]
MDQVGKSHQQALVSVITEAAQSQLKNEVTESPQCPTSSSELSPTSVTQSISSGPTNKKLSLVANTNSACMPEVVRQNSSN...
>KAF7152831.1 hypothetical protein RHSIM_Rhsim01G0241100 [Rhododendron simsii]
MASTHITPQTNFSSFSKAQFMASSATSFTDLLAGDYPSSSAVSRGLSDRIAERTGSGVPKFKSIPPPSIPTSPHAVSPSF...
```

### 2.07 `ProteinPropertyFromExpasy.py [FASTA_FILE]`

**Function Description:** Batch obtain physicochemical properties of proteins from ExPASy (https://web.expasy.org/protparam). 

- **FASTA_FILE: ** Provide protein sequences in FASTA format, which can be a file containing multiple sequences. 

**Generated File:** 
- `expasy_output.csv`(Table file, containing physicochemical properties of some protein sequences). 

**Example:**

For example, `example/text.fa` is a FASTA file of protein sequences: 
```
>KAF7112153.1 hypothetical protein RHSIM_RhsimUnG0257300 [Rhododendron simsii]
MASVKNRVRNKLFKCFRPAAIDDDPIKPDATDGPGNSVFTSISGKGKSGKISNLLSGEKGKVYSEGGDAGGDRSNKERSH...
>KAF7112159.1 hypothetical protein RHSIM_RhsimUnG0256100 [Rhododendron simsii]
MASNTQSSFEDFLPIMAHKLGGEALIGELCNGFRLLMDGDKGVITFDSLKKNAAVLGLQELTDGDLRSMLREGDFDGDGA...
...
>KAF7152831.1 hypothetical protein RHSIM_Rhsim01G0241100 [Rhododendron simsii]
MASTHITPQTNFSSFSKAQFMASSATSFTDLLAGDYPSSSAVSRGLSDRIAERTGSGVPKFKSIPPPSIPTSPHAVSPSF...
```
Execute command:
```bash
python ProteinPropertyFromExpasy.py example/text.fa
``` 
The corresponding results can then be output:  
```
id	Number of amino acids	Molecular weight	Theoretical pI	Instability index	Aliphatic index	Grand average of hydropathicity (GRAVY)
KAF7112153.1	242	26387.53	9.6	46.09	65.33	-0.683
KAF7112159.1	215	23735.82	4.91	46.08	73.02	-0.329
KAF7154833.1	86	9692.81	9.84	59.07	40.81	-0.852
KAF7153261.1	397	43507.84	9.07	56.96	61.64	-0.763
KAF7152831.1	548	60491.94	8.44	57.65	43.27	-0.965
```

### 2.08 `FeaturesBaseComponents.py [FASTA_FILE] [TABLE]`

**Function Description:** Organelle genome specific, feature extraction and base composition statistics. If you want to truncate a fasta file based on start and end positions, you can also use this script!   

- **FASTA_FILE: ** A FASTA file containing only one sequence. 
- **TABLE: ** A table containing feature names, groups, and start positions. The first column is the genome, the second column is the gene, the third column is the gene start position, and the fourth column is the gene end position. "Gene" is a nominal concept; you can assign any fragment to a group. 

**Usage scenario:** If the FASTA file is a mitochondrial genome and the table file's first column contains features (e.g., tRNA, CDS, etc.) and the second column contains feature names (e.g., gene names, D-Loop, etc.), you can obtain a table showing the base usage for each region.  

**Notes:** Use with caution if the sequence contains internal stop codons, and note that if the gene is not encoded on the + strand, the reverse complement sequence will be extracted.  

**Generated File:** 
- `ex_seq.fasta`(FASTA file, extracted short fragment sequences).
- `Base_composition.txt` (Table of ATGC base composition percentages).  

**Example:**

For example,  `example/all.fa` is a FASTA file containing short fragment sequences:  
```
>test dna [LEN=30]
GATTTAGCAG
TAAGATGAGA
TCATCCCCAG
```
`example/matrix.txt`  is the feature position matrix:  
```
A;B	ab	9	11
A	a1	16	21
A	a2	6	10
b	b	14	23
```
Execute command:
```bash
python FeaturesBaseComponents.py example/all.fa example/matrix.txt
``` 
The corresponding results can then be output: 
```
#ex_seq.fasta
>ab
AGT
>a1
TGAGAT
>a2
AGCAG
>b
GATGAGATCA

>GR%A
AGCAGTTGAGAT
>GR%B
AGT
>GR%b
GATGAGATCA
>$all
GATTTAGCAGTAAGATGAGATCATCCCCAG
>$other
GATTTAATCCCCAG

#Base_composition.txt
SEQ	A	T	G	C
ab	1	1	1	0	
a1	2	2	2	0	
a2	2	0	2	1	
b	4	2	3	1	
GR%A	4	3	4	1	
GR%B	1	1	1	0	
GR%b	4	2	3	1	
$all	10	7	7	6	
$other	4	4	2	4	
```

### 2.09 `ExAndRename.py [MAP_FILE] [FASTA_FILE]`

**Function Description:** Extract partial sequences from a FASTA file and modify their names according to rules.  

- **MAP_FILE: ** In the provided information, the first column lists the sequence names to be extracted or renamed, corresponding to the text content after the ">" symbol and before the first space in the FASTA file; if there is no space, it refers to the complete sequence identifier after the ">" symbol. The second column is the new name desired for the modification. When the content of the first column is the same as the second column, this operation is equivalent to performing the function of code 2.06.  
- **FASTA_FILE: ** A sequence file in Fasta format, which includes all sequences, such as a whole genome fa file, pep, or CDS sequences.  

**Usage scenario:** Suitable for extracting chromosomes from whole genome sequences and modifying their names. 

**Generated File:** 
- `subset_fasta.faa`(FASTA file. If there is excess content in the map table, a prompt will be given).                

**Example:**

For example, `eexample/map.txt`  is a table corresponding old IDs (first column) to new IDs (second column):  
```
KAF7154833.1	a
KAF7152831.1	b
aaa	c
```
`example/text.fa` contains all sequences:  
```
>KAF7112153.1 hypothetical protein RHSIM_RhsimUnG0257300 [Rhododendron simsii]
MASVKNRVRNKLFKCFRPAAIDDDPIKPDATDGPGNSVFTSISGKGKSGKISNLLSGEKGKVYSEGGDAGGDRSNKERSH...
>KAF7112159.1 hypothetical protein RHSIM_RhsimUnG0256100 [Rhododendron simsii]
MASNTQSSFEDFLPIMAHKLGGEALIGELCNGFRLLMDGDKGVITFDSLKKNAAVLGLQELTDGDLRSMLREGDFDGDGA...
...
>KAF7152831.1 hypothetical protein RHSIM_Rhsim01G0241100 [Rhododendron simsii]
MASTHITPQTNFSSFSKAQFMASSATSFTDLLAGDYPSSSAVSRGLSDRIAERTGSGVPKFKSIPPPSIPTSPHAVSPSF...
```
Execute command:
```bash
python ExAndRename.py example/map.txt example/text.fa
``` 
The following can then be generated:  
```
>a
MFRFAMWNRGWSWWTSPTDKERVDVVMETKGGKKKSSSSSTSTSSSRSSSLQYEAPLGYSIEDIRPNGGIEKFRSAAYSN...

>b
MASTHITPQTNFSSFSKAQFMASSATSFTDLLAGDYPSSSAVSRGLSDRIAERTGSGVPKFKSIPPPSIPTSPHAVSPSF...
```
It should be noted that the 'aaa' sequence does not exist, so it was not extracted.  
       
### 2.10 `BatchFastaToPam.py [FASTA_FILE_DIR]`

**Function Description:** Batch convert aligned FASTA files to PAML alignment files. 

- **FASTA_FILE_DIR: ** Directory path name, containing the aligned FASTA format files to be converted within this directory.  

**Notes:** The folder must not contain unaligned sequence files or any other files, otherwise an error will occur!

**Generated File:** 
- `pamlfile`(Folder, containing the FASTA files to be converted with a .pam suffix).     

**Example:**

For example, the `example/ali_fasta` folder contains the FASTA files to be converted:  
```
example/
└── ali_fasta/
    ├── OG0002719.fa   
    └── OG0002724.fa
```
Execute command:
```bash
python BatchFastaToPam.py example/ali_fasta
```
The corresponding results will be output to the `pamlfile`  folder:
```
pamlfile/
├── OG0002719.fa.pam   
└── OG0002724.fa.pam
```

### 2.11 `ReassignSequence.py [IN_FASTA_FILE_DIR] [MATRIX_FILE] [OUT_FASTA_FILE_DIR]`

**Function Description:** Distribute sequences from a FASTA file into different FASTA files as required.  

- **IN_FASTA_FILE_DIR: ** Directory path name, containing the FASTA format sequence files to be redistributed within this directory. These can be DNA, CDS, transcripts, proteins, or other sequences.  
- **MATRIX_FILE: ** Matrix file location, tab-separated, including a header row! The first item of each row is the new file name after redistribution, and the remaining items are the sequence names contained in that file.  
- **OUT_FASTA_FILE_DIR: ** Directory path name, output path.  

**Usage scenario:** ① During the extraction of sequences for each gene family of single-copy orthologs, downloaded CDS sequences are grouped according to gene families and assigned to new, distinct files. This is used for subsequent matching of CDS and protein sequences. The matrix file is Orthogroups/Orthogroups.tsv (MATRIX_FILE, refer to the example file example/seq_matrix2.txt). You only need to download the fna file for each species from NCBI (important: use the cut command to split columns and retain only the first column, so that each sequence name contains only the ID number!), place them in the same folder (IN_FASTA_FILE_DIR), and then specify the output file to distribute the CDS files of different species into fasta files named after the gene family names. ② Extract genes from the same gene family for combined analysis.             

**Notes:** The index table must contain a header row. It can be a standard matrix with the same number of rows and columns, but this is not mandatory.  

**Generated File:** 
- `<OUT_FASTA_FILE_DIR>` (Folder, containing the redistributed sequences).       

**Example:**

For example, the `example/ali_fasta`  folder contains the FASTA files to be redistributed:  
```
example/
└── ali_fasta/
    ├── OG0002719.fa   
    └── OG0002724.fa
```
`example/seq_matrix.txt` specifies the grouping for all sequences in the FASTA file. The content of the first row is not important:  
```
Orthogroup	A	B	C	
OG01	XP_010706234.2	XP_032302195.1	jirou002500.1	
OG02	NP_001026572.1	XP_038029232.1		
OG03	XP_032302195.1	XP_048781468.1		
OG04	jirou002516.1	XP_015134329.2	XP_035425170.1	XP_035170945.1
```
Execute command:
```bash
python ReassignSequence.py example/ali_fasta example/seq_matrix.txt out
``` 
The corresponding sequences can then be extracted from all FASTA files and placed into different files within the `out` directory: 
```
out/
├── OG01.fna   
├── OG02.fna 
├── OG03.fna 
└── OG04.fna

#OG01
>XP_010706234.2	
...
>XP_032302195.1	
...
>jirou002500.1
...

#OG02
>NP_001026572.1	
...
>XP_038029232.1	
...

...
```

### 2.12 `BatchAlignedProteinToDNA.py [-h] [-c CODON] [-m MAPFILE] [-p PEP] [-C CDS] [-s SUFFIX_P] [-S SUFFIX_C]`

**Function Description:** If you have a protein alignment file and want to obtain the corresponding codon-aligned CDS sequences, you can use this script. In simple terms, it batch-converts aligned protein sequences back into DNA sequences. This script can filter out:    
① Sequences whose CDS length is not a multiple of 3;    
② Sequences where the CDS and protein sequences do not match;    
③ Sequences containing unknown nucleotides (N).  

**Parameter Description:** 

```bash
options:
  -h, --help            show this help message and exit
  -c, --codon CODON     Codon Table File.
  -m, --mapfile MAPFILE
                        Protein Sequence Names and their Corresponding CDS Sequence Names Table.
  -p, --pep PEP         Directory containing Protein Sequences.
  -C, --cds CDS         Directory containing CDS Sequences.
  -s, --suffix_p SUFFIX_P
                        Protein sequence file extensions.
  -S, --suffix_c SUFFIX_C
                        CDS sequence file extensions.
``` 

**Usage scenario:** During the search for homologous gene families across multiple species using OrthoFinder, aligned protein sequence files of single-copy orthologous genes are generated in the `WorkingDirectory/Alignments_ids` directory. Extract the single-copy orthologous gene families (the list of single-copy gene families is located in `Orthogroups/Orthogroups_SingleCopyOrthologues.txt`) into a folder using a for loop (PEP parameter). Download the corresponding CDS sequences from databases such as NCBI (ensuring CDS sequence IDs match the protein sequence IDs), and use script 2.11 to extract the unaligned CDS sequences corresponding to the protein sequences into another folder (CDS parameter). The file `SequenceIDs.txt` in the OrthoFinder output directory (`WorkingDirectory`) serves as the mapping file between protein names and CDS names (MAPFILE parameter).

**Notes:** The SequenceIDs.txt file generated automatically by the software needs to be manually split by colon and space, and extraneous parts should be removed. For details, please refer to the example file.  

**Generated File:** 
- `output` (Folder for storing aligned CDS sequences; refer to `example/output` for sample files generated by running the above command.).  
- `err_cds.txt` (Error log file, displaying the sequences that were filtered out. This file will not be generated if no sequences are filtered.).

**Example:**

For example, the `example` folder contains the required files:
```
example/
├── cod.txt
├── SequenceIDs.txt
├── cds/
│  ├── OG0002719.fna  
│  ├── ... 
│  └── OG0002837.fna
└── pep/
    ├── OG0002719.fa  
    ├── ... 
    └── OG0002837.fa

#cod.txt
A	GCG 
A	GCA 	
A	GCT 
...
Y	TAT 
Y	TAC 
*	TGA 
*	TAG
*	TAA

#SequenceIDs.txt
0_0	XP_010706234.2
1_7	XP_032302195.1
2_3	XP_021240136.1
3_3	XP_040400452.1
...
7_222	XP_027313668.2
8_291	NP_001025904.2
9_249	XP_048815064.1
10_2438	jirou002303.1
```
The protein sequence files have the suffix `.fa`, and the CDS sequence files have the suffix `.fna`. Execute the command: 
```bash
python BatchAlignedProteinToDNA.py -c example/cod.txt -m example/SequenceIDs.txt -p example/pep -C example/cds -s "fa" -S "fna"
```
The aligned CDS files will then be saved in separate files within the `output` directory:  
```
output/
├── OG0002719.fa   
├── OG0002724.fa 
└── OG0002729.fa
```  
Some sequences may also have issues, which can be viewed in detail in the `err_cds.txt` file:  
```
OG0002721.fa	Sequence mismatch
OG0002761.fa	There is N in the CDS.
OG0002837.fa	The CDS is not a multiple of 3.
```  

### 2.13 `Extract4DTv.py [-h] [-c CODON] [-m MAPFILE] [-p PEP] [-C CDS] [-s SUFFIX_P] [-S SUFFIX_C]`

**Function Description:** Batch extract 4DTv (fourfold degenerate sites) from protein sequence alignment results.  

**Parameter Description:** All parameters are consistent with those of script 2.12. The code content is essentially the same, differing only in the generated file names.  

```bash
options:
  -h, --help            show this help message and exit
  -c, --codon CODON     Codon Table File.
  -m, --mapfile MAPFILE
                        Protein Sequence Names and their Corresponding CDS Sequence Names Table.
  -p, --pep PEP         Directory containing Protein Sequences.
  -C, --cds CDS         Directory containing CDS Sequences.
  -s, --suffix_p SUFFIX_P
                        Protein sequence file extensions.
  -S, --suffix_c SUFFIX_C
                        CDS sequence file extensions.
``` 

**Usage scenario:** Phylogenetic tree construction for homologous genes.  

**Generated File:** 
- `4dtv`(Folder for storing the extracted 4DTv sites; refer to `example/4dtv` for sample files generated by running the above command.). 
- `err_4dtv.txt`(Error log file, displaying the sequences that were filtered out. This file will not be generated if no sequences are filtered.).  

**Example:**

For example, the `example` folder contains the required files:
```
example/
├── cod.txt
├── SequenceIDs.txt
├── cds/
│  ├── OG0002719.fna  
│  ├── ... 
│  └── OG0002837.fna
└── pep/
    ├── OG0002719.fa  
    ├── ... 
    └── OG0002837.fa

#cod.txt
A	GCG 
A	GCA 	
A	GCT 
...
Y	TAT 
Y	TAC 
*	TGA 
*	TAG
*	TAA

#SequenceIDs.txt
0_0	XP_010706234.2
1_7	XP_032302195.1
2_3	XP_021240136.1
3_3	XP_040400452.1
...
7_222	XP_027313668.2
8_291	NP_001025904.2
9_249	XP_048815064.1
10_2438	jirou002303.1
```  
The protein sequence files have the suffix `.fa`, and the CDS sequence files have the suffix `.fna`. Execute the command:  
```bash
python Extract4DTv.py -c example/cod.txt -m example/SequenceIDs.txt -p example/pep -C example/cds -s "fa" -S "fna"
``` 
The 4DTv sites will then be extracted and saved in separate files within the `4dtv` directory:  
```
4dtv/
├── OG0002719.fa   
├── OG0002724.fa 
└── OG0002729.fa
```  
Some sequences may also have issues, which can be viewed in detail in the `err_4dtv.txt` file:
```
OG0002721.fa	Sequence mismatch
OG0002761.fa	There is N in the CDS.
OG0002837.fa	The CDS is not a multiple of 3.
```  

### 2.14 `MergeSequences.py [MATRIX_FILE] [FASTA_FILE_DIR] [SUFFIX] [ORDER_LIST (Optional parameter)]`

**Function Description:** Advanced sequence concatenation script.  

- **MATRIX_FILE: ** Matrix file location, tab-separated, must include a header row! Each column represents a sample, and each row corresponds to a sequence. The first item in each row is the sequence name (i.e., the FASTA filename without the suffix). The intersection of rows and columns specifies the sequence name for each sample.  
- **FASTA_FILE_DIR: ** Folder path name; this directory contains the aligned FASTA files to be concatenated. The file names have no specific requirements, as long as they include all the sequence names listed in the MATRIX_FILE.  
- **ORDER_LIST: ** Specify the concatenation order. By defining the order, you can either exclude certain sequences or set a specific sequence for concatenation. If not specified, all sequences will be concatenated by default in the order of the hash value of their sequence names.  

**Notes:** The folder must not contain unaligned sequence files, as this may cause concatenation errors!  

**Generated File:** 
- `<FASTA_FILE_DIR>.fasta` (FASTA file, with each sequence header corresponding to the sample name from the first row of the matrix.)  
- `order.true` (Actual concatenation order.)  

**Example:**

For example, the `example` folder contains the required files:  
```
example/
├── seq_matrix.txt
├── order.txt
└── 4dtv/
    ├── OG0002719.fa  
    ├── OG0002724.fa
    └── OG0002729.fa

#seq_matrix.txt
Orthogroup	s1	s2	s3	s4	s5	...
OG0002719	XP_010706234.2	XP_032302195.1	XP_021240136.1	XP_040400452.1	XP_032063692.1	...
OG0002724	XP_010727090.1	XP_015706975.1	XP_021239881.1	XP_040400939.1	XP_032038059.1	...
OG0002729	XP_010706070.1	XP_015712434.1	XP_021239916.1	XP_040401487.1	XP_032053636.1	...

#order.txt
OG0002729
OG0002724
```  
Execute the command:  
```bash
# Run the following command to perform full concatenation without specifying the order:
python MergeSequences.py example/seq_matrix.txt example/4dtv

# To specify the concatenation order, run the following command:
python MergeSequences.py example/seq_matrix.txt example/4dtv example/order.txt
``` 
The concatenated sequence file and the actual concatenation order file will then be generated, with the concatenated sequence file:  
```
>s1
...
>s2
...
``` 

### 2.15 `BatchGenerationCodeML_CTL.py [PAML_FILE_DIR] [TREE_FILE]`

**Function Description:** Batch generate configuration files for CodeML.  

- **PAML_FILE_DIR: ** Directory containing the PAML-formatted alignment files. When running this script, the directory must contain the alignment files intended for selection pressure analysis. Avoid using relative paths as they may prevent the script from correctly reading the required file paths.  
- **TREE_FILE: ** Tree file path (relative to the CodeML runtime directory). The file does not need to exist when running this script, but it must be accessible by the specified path when executing the CodeML program.  

**Notes:** This script only generates configuration files. Please note that the tree file path imported by the script is not necessarily the same as the tree file path during CodeML execution! The configuration template uses the Branch model; if you have other requirements, you can directly modify the generated configuration files.   

**Generated File:** 
- `codemlnull` (Folder for configuration files based on the null hypothesis.) 
- `codeml2`(Folder for configuration files based on the alternative hypothesis.)

**Example:**

For example, the `example` folder contains the required subfolder `paml_file`:  
```
example/
└── paml_file/
    ├── OG0005572.fa.nuc  
    ├── OG0005964.fa.nuc
    ├── OG0008612.fa.nuc
    └── OG0010932.fa.nuc

#OG0005572.fa.nuc
11	201
s0  
ATGATCATCCCGGTCAGGTGTTTCACGTGCGGCAAAATCGTCGGA...
s1  
ATGATCATCCCGGTGCGATGCTTCACGTGCGGCAAGATCGTGGGC...
...
s10  
ATGATCATCCCGGTCAGGTGCTTCACGTGCGGCAAAATCGTTGGA...
```  
Execute the command:  
```bash
python BatchGenerationCodeML_CTL.py example/paml_file "./out/a.tree"
```
Note that "./out/a.tree" is not a file required by this script, but rather the tree path to be written into the configuration files. The following folders will be generated:
```
#Configuration files based on the null hypothesis
codemlnull/
├── OG0005572.fa.nuc.ctl  
├── OG0005964.fa.nuc.ctl
├── OG0008612.fa.nuc.ctl
└── OG0010932.fa.nuc.ctl

#Configuration files based on the alternative hypothesis
codeml2/
├── OG0005572.fa.nuc.ctl  
├── OG0005964.fa.nuc.ctl
├── OG0008612.fa.nuc.ctl
└── OG0010932.fa.nuc.ctl

#For example, a configuration file based on the null hypothesis: OG0005572.fa.nuc.ctl

      seqfile = ../example/paml_file/OG0005572.fa.nuc  * sequence data filename
     treefile = ./out/a.tree  * tree file name

      outfile = ./output0/OG0005572.fa.nuc/abc.txt           * main result file name
   
        noisy = 9  * 0,1,2,3,9: how much rubbish on the screen
      verbose = 2  * 0: concise; 1: detailed, 2: too much
      runmode = 0  * 0: user tree;  1: semi-automatic;  2: automatic
                   * 3: StepwiseAddition; (4,5):PerturbationNNI; -2: pairwise

      seqtype = 1  * 1:codons; 2:AAs; 3:codons-->AAs
    CodonFreq = 2 * 0 : 1/61 each, 1:F1X4, 2:F3X4, 3:codon table
                   * 4:F1x4MG, 5:F3x4MG, 6:FMutSel0, 7:FMutSel
        model = 0
                   * models for codons:
                      * 0:one, 1:b, 2:2 or more dN/dS ratios for branches, 6:FromCodon
                   * models for AAs or codon-translated AAs:
                      * 0:poisson, 1:proportional, 2:Empirical, 3:Empirical+F
                      * 6:FromCodon, 7:AAClasses, 8:REVaa_0, 9:REVaa(nr=189)

      NSsites = 0 * 23 24 25 26   * 23 24 25 26 * 0:one w; 1:NearlyNeutral; 2:PositiveSelection; 3:discrete;
                   * 4:freqs; 5:gamma; 6:2gamma; 7:beta; 8:beta&w+; 9:beta&gamma;
                   * 10:beta&gamma+1; 11:beta&normal>1; 12:0&2normal>1;
                   * 13:3normal>0; 
                   * 22:M2a_Old(M2a_rel); 
                   * 23:Tgamma; 24:Tinvgamma; 25:Tgamma+1; 26:Tinvgamma+1.

        clock = 0  * 0:no clock, 1:global clock; 2:local clock
       aaDist = 0  * 0:equal, +:geometric; -:linear, 1-6:G1974,Miyata,c,p,v,a
   aaRatefile = ../dat/wag.dat * for aa seqs under model = 3 (empirical+F)
                   * dayhoff.dat, jones.dat, wag.dat, mtmam.dat, or your own

    fix_kappa = 0  * 1: kappa fixed, 0: kappa to be estimated
        kappa = 3  * initial or fixed kappa
    fix_omega = 0  * 1: omega or omega_1 fixed, 0: estimate
        omega = 1  * initial or fIf yoixed omega, for codons or codon-based AAs

    fix_alpha = 1  * 0: estimate gamma shape parameter; 1: fix it at alpha
        alpha = 0. * initial or fixed alpha, 0:infinity (constant rate)
       Malpha = 0  * different alphas for genes
        ncatG = 10  * # of categories in dG of NSsites models

        getSE = 0  * 0: don't want them, 1: want S.E.s of estimates
 RateAncestor = 0  * (0,1,2): rates (alpha>0) or ancestral states (1 or 2)
   Small_Diff = 1e-8
*    cleandata = 1  * remove sites with ambiguity data (1:yes, 0:no)?
*  fix_blength = 1  * 0: ignore, -1: random, 1: initial, 2: fixed
*       method = 0  * Optimization method 0: simultaneous; 1: one branch a time

* Genetic codes: 0:universal, 1:mammalian mt., 2:yeast mt., 3:mold mt.,
* 4: invertebrate mt., 5: ciliate nuclear, 6: echinoderm mt., 
* 7: euplotid mt., 8: alternative yeast nu. 9: ascidian mt., 
* 10: blepharisma nu., 11: Yang's regularized code 
* These codes correspond to transl_table 1 to 11 of GenBank.
```  

### 2.16 `ParsingCodeMLResults.py [MOD0_DIR] [MOD2_DIR] `

**Function Description:** Batch parse CodeML results. If CodeML was run using the scripts generated by 2.15, the results will be generated in the `m0` and `m2` folders.   

- **MOD0_DIR: ** Results generated based on the null hypothesis.
- **MOD2_DIR: ** Results generated based on the alternative hypothesis.

**Generated File:** 
- `result.txt`  (Table, may require manual arrangement).

**Example:**

For example, the `example/codeml` folder contains CodeML results under both hypotheses: 
```
example/
└── codeml/
        ├── m0/
        │     ├── OG0002719_m0.txt  
        │     ├── OG0002724_m0.txt
        │     └── OG0002729_m0.txt
        └── m2/
               ├── OG0002719_m2.txt  
               ├── OG0002724_m2.txt
               └── OG0002729_m2.txt
```  
Execute the command:  
```bash
python ParsingCodeMLResults.py example/codeml/m0 example/codeml/m2
```
The result file `result.txt` will then be generated:
```
path	flag	ntime	np	lnL	omega
example/codeml/m0/OG0002719_m0.txt	null	20	22	-5245.294651	0.23258
example/codeml/m0/OG0002724_m0.txt	null	20	22	-6740.507258	0.04957
example/codeml/m0/OG0002729_m0.txt	null	20	22	-3588.001403	0.07700
example/codeml/m2/OG0002719_m2.txt	m2	20	23	-5237.515508	0.18756 0.61602
example/codeml/m2/OG0002724_m2.txt	m2	20	23	-6753.685334	0.03988 0.06959
example/codeml/m2/OG0002729_m2.txt	m2	20	23	-3584.953121	0.08111 0.00010
```   

> ## Comparative Genomics - Homologous Gene Phylogenetic Tree Construction and Selection Pressure Analysis Pipeline (I)          
> In comparative genomics analyses, after scanning for homologous genes, 4DTv or phylogenetic tree analysis is typically performed. The process of extracting 4DTv sites can be completed using scripts 2.11, 2.13, and 2.14. Additionally, the CodeML program from the PAML package is used to perform selection pressure analysis on the identified single-copy genes. First, script 2.10 is used to convert the files obtained from script 2.12 into the required format. Next, configuration (ctl) files must be set up—a tedious process that can be streamlined by using script 2.15 to batch-generate these files. Following this, the programs can be run in bulk using loops. After the programs finish, script 2.16 is used to parse the results, pairing the outputs from the m0 and m2 models. This yields lnL0 and lnL2 values. The absolute value of (lnL2 - lnL0) × 2 follows a chi-square distribution with degrees of freedom equal to np2 - np0. The significance can then be calculated using Excel's CHISQ.DIST.RT function.         

### 2.17 `SplitAXT.py [AXT_FILE]`
     
**Function Description:** Split a single AXT file into multiple AXT files, with each file containing only one pair of sequence alignments. 

- **AXT_FILE: ** The AXT file to be split.

**Usage scenario:** After generating codon alignment files using script 2.12, if further 4DTv analysis is required, the Perl script `convert_fasta_to_axt.pl` (adaptively modified) should be used to convert the alignments into AXT format. This script can then split the resulting AXT file (produced by the aforementioned script) into individual files, each containing one sequence pair alignment.  

**Notes:** This script only supports AXT files where the sequence pair names contain digits. 

**Generated File:** 
- `<Sequence pair>.axt-split`(multiple axt files).

**Example:**

For example, the `example/test.axt` file is the AXT file to be split, with the following content:
```
5_13054-1_13901
------ ... CTGCAAAGAAGGAT
------ ... CCGCAAAGAAGGAC

5_13054-8_15414
------ ... CTGCAAAGAAGGAT
------ ... CTGCAAAGAAGGAT
```  
Execute the command:  
```bash
python SplitAXT.py example/test.axt
          
# Sometimes you may need to process files in batch.
for i in `ls *axt`;do python SplitAXT.py $i ;done
```
In the example, two files will be generated:
```
#5_13054-1_13901.axt-split
------ ... CTGCAAAGAAGGAT
------ ... CCGCAAAGAAGGAC

#5_13054-8_15414.axt-split
------ ... CTGCAAAGAAGGAT
------ ... CTGCAAAGAAGGAT
```  

> ## Comparative Genomics - Homologous Gene Phylogenetic Tree Construction and Selection Pressure Analysis Pipeline (II)          
> You can refer to https://yanzhongsino.github.io/2022/09/07/bioinfo_Ks_batch.calculation.Ks to calculate Ka, Ks, and 4DTv values. Since the calculate_4DTV_correction.pl script only supports 4DTv calculation for a single pair of sequences, you can use script 2.17 to split the AXT file.                  

### 2.18 `BaseSiteInformation.py [GFF_FILE] [Q_FILE]`

**Function Description:** Extract corresponding gene data based on specified chromosomal positions and base site information, such as which CDS region of a transcript the site falls into, as well as positional information of the CDS or transcript, facilitating subsequent annotation analysis.  

- **GFF_FILE: ** Genome GFF file; only mRNA and CDS features should be retained, and each mRNA entry must appear above the CDS features it contains. You may choose to manually sort the GFF file before running the script!  
- **Q_FILE: ** Lookup table containing the entries to be searched, must include a header row, and at least two columns: the first column must be the chromosome ID, and the second column must be the corresponding position on the chromosome.  

**Usage scenario:** Advanced versions are available in scripts 2.22 and 2.23, which use algorithms such as random forest to identify variant sites between different populations or varieties, requiring the identification of the genes to which these variant sites belong.

**Generated File:** 
- `out_<Q_FILE>.xls`(Table, with the first and fourth columns being gene names, the second column indicating whether it is in a CDS region (CDS/noCDS), the third column showing the start and end positions of the CDS and the ORF start site, the fifth column being the chromosome ID, followed by gene start position, score, and number of CDS per gene.) 

**Example:**

For example, the `example` folder contains two files: 
```
example/
├── genome.gene.gff   
└── base_loc.txt

#genome.gene.gff
chr6	mod	mRNA	61479002	61483066	0.999299	-	.	ID=shibie_GLEAN_10005360;
chr6	mod	CDS	61482857	61483066	.	-	0	Parent=shibie_GLEAN_10005360;
chr6	mod	CDS	61480913	61481015	.	-	0	Parent=shibie_GLEAN_10005360;
chr6	mod	CDS	61480545	61480595	.	-	2	Parent=shibie_GLEAN_10005360;
chr6	mod	CDS	61479002	61480122	.	-	2	Parent=shibie_GLEAN_10005360;
...
unplaced_scaffold9	mod	CDS	9320	9504	.	-	0	Parent=shibie_GLEAN_10000001;
unplaced_scaffold9	mod	CDS	7041	7117	.	-	1	Parent=shibie_GLEAN_10000001;
unplaced_scaffold9	mod	CDS	6377	6435	.	-	2	Parent=shibie_GLEAN_10000001;
unplaced_scaffold9	mod	CDS	4737	5270	.	-	0	Parent=shibie_GLEAN_10000001;

#base_loc.txt
CHROM	POS	IncMSE(Importance)	IncNodePurity	CHROM	POS	REF	ALT	BYQ10	BYQ3
chr6	1508314	-1.134209981	229.6628618	chr6	1508314	A	T	W	W
chr6	2238474	1.503310682	85.34757716	chr6	2238474	G	C	G	G
chr6	2692990	0.23640024	195.3846105	chr6	2692990	G	A	R	R
chr6	2914183	-0.436014622	115.9339111	chr6	2914183	C	A	C	M
chr6	3013236	0.922900751	815.7366022	chr6	3013236	T	C	T	T
...
chr8	51046810	1.229196235	487.9762709	chr8	51046810	C	T	C	C
chr8	51530461	1.487830764	1463.658822	chr8	51530461	C	T	C	C
chr8	53281836	1.090568252	684.2414242	chr8	53281836	C	A	C	C
chr8	53557595	0.954201007	510.2543934	chr8	53557595	T	G	T	T
```  
Execute the command:  
```bash
python BaseSiteInformation.py example/genome.gene.gff example/base_loc.txt
```
The result file `out_base_loc.txt.xls` will then be generated:  
```
gene_name	CDS/noCDS	CDS(start,end,codon start pos)	gene	ChrID	gene_start_pos	gene_end_pos	score	CDS_num	CHROM	POS	IncMSE(Importance)	IncNodePurity	CHROM	POS	REF	ALT	BYQ10	BYQ3
shibie_GLEAN_10003636	noCDS	-	shibie_GLEAN_10003636	chr6	1479415	1511307	0.99885	21	chr6	1508314	-1.134209981	229.6628618	chr6	1508314	A	T	W	W
shibie_GLEAN_10003659	CDS	(2238236, 2238538, '2')	shibie_GLEAN_10003659	chr6	2227463	2239321	0.999821	7	chr6	2238474	1.503310682	85.34757716	chr6	2238474	G	C	G	G
-	-	-	-	-	-	-	-	-	chr6	2692990	0.23640024	195.3846105	chr6	2692990	G	A	R	R
...
shibie_GLEAN_10001336	noCDS	-	shibie_GLEAN_10001336	chr8	51009683	51060709	0.998932	23	chr8	51046810	1.229196235	487.9762709	chr8	51046810	C	T	C	C
-	-	-	-	-	-	-	-	-	chr8	51530461	1.487830764	1463.658822	chr8	51530461	C	T	C	C
shibie_GLEAN_10001391	noCDS	-	shibie_GLEAN_10001391	chr8	53278535	53293780	0.847545	8	chr8	53281836	1.090568252	684.2414242	chr8	53281836	C	A	C	C
shibie_GLEAN_10001401	noCDS	-	shibie_GLEAN_10001401	chr8	53548014	53561536	0.9986	10	chr8	53557595	0.954201007	510.2543934	chr8	53557595	T	G	T	T
```   

### 2.19 `MaskSeq.py [FASTA_FILE] [TABLE_FILE] [TARG (Optional parameter)]`
       
***To be optimized!***

**Function Description:** Mask specific regions in a FASTA file (replace with TARG).  

- **FASTA_FILE: ** FASTA file containing multiple sequences; for a genome, this includes sequences of many chromosomes, with the content following ">" being the sequence name.                          
- **TABLE_FILE: ** Three-column table without a header row. The first column is the sequence name (must exactly match the name in the FASTA file), and the second and third columns are the start and end positions of the masking region (1-based indexing, can be directly copied from a GFF file).             
- **TARG: ** Masking character: the bases in the specified regions will be replaced with this character. By default, the bases at the specified positions are replaced with N, but you can also specify a different replacement character. 
   
**Usage scenario:** In genome analysis, certain sequences (e.g., repetitive sequences) are masked to reduce computational load during analysis.  

**Notes:** The TARG parameter must be a single character. 

**Generated File:** 
- `maskseq_<FASTA_FILE>` (FASTA file with specified regions masked)    

**Example:**

For example, the `example` folder contains two files:
```
example/
├── Chr.fa   
└── masktbl.txt

#Chr.fa
>Chr1
ATCGGCATATATCTTATTATATTTCCCCAAA
>Chr2
ATCGGCATATATCTTATTATATTTCCCCAAA
TTCCATCA
>MT
ATCGGCATATATCTTATTATATTTCCCCAAA

#masktbl.txt
Chr1	2	8
Chr2	1	5
Chr2	7	10
Chr3	10	20
```  
Execute the command:  
```bash
# Replaced with N by default.
python MaskSeq.py example/Chr.fa example/masktbl.txt

# Replaced with ?.
python MaskSeq.py example/Chr.fa example/masktbl.txt "?"
```
The segment masking is then completed: 
```
#Replaced with N by default.
>Chr1
ANNNNNNNATATCTTATTATATTTCCCCAAA
>Chr2
NNNNNCNNNNATCTTATTATATTTCCCCAAATTCCATCA
>MT
ATCGGCATATATCTTATTATATTTCCCCAAA

#Replaced with ?.
>Chr1
A???????ATATCTTATTATATTTCCCCAAA
>Chr2
?????C????ATCTTATTATATTTCCCCAAATTCCATCA
>MT
ATCGGCATATATCTTATTATATTTCCCCAAA
```  

### 2.20 `BaseCompositionCalculation.py [FASTA_FILE] [TER_CODE (Optional parameter)]`
       
**Function Description:** Calculate the number of bases at each site of each sequence in the CDS sequences, such as A1, T1, G1, G3, etc. 

- **FASTA_FILE: ** A FASTA file containing multiple sequences, which must be nucleotide sequences. 
- **TER_CODE: ** List of stop codons. The default values are TAG, TAA, and TGA from the standard genetic code. If custom stop codons are specified, ensure they are separated by half-width commas without extra whitespace. If you wish to include stop codons in the statistics, you can input NNN.  

**Usage scenario:** When performing codon usage bias analysis, parameters such as GC12 and GC3 can be further calculated based on the results from this script.            

**Generated File:** 
- `BaseComposition.txt`(Table file containing the count of bases at each site, with the last column being the total base count.) 

**Example:**

For example, the `example/base_cds.fa` file is a FASTA file containing all CDS sequences:
```
>1
AAAATAG
>2
ATTATTTAG
>3
ATCGATCGATCGTAG
```  
Execute the command:
```bash
# Default removal of standard stop codons:
python BaseCompositionCalculation.py example/base_cds.fa

# Hope to count up to the stop codon:
python BaseCompositionCalculation.py example/base_cds.fa NNN

# Custom stop codon:
python BaseCompositionCalculation.py example/base_cds.fa TGA,TAA
```
The statistics can then be completed:
```
#Default removal of standard stop codons:
name	A1	T1	G1	C1	A2	T2	G2	C2	A3	T3	G3	C3	all
1	-	-	-	-	-	-	-	-	-	-	-	-	-
2	2	0	0	0	0	2	0	0	0	2	0	0	6	
3	1	1	1	1	1	1	1	1	1	1	1	1	12	

#Hope to count up to the stop codon:
name	A1	T1	G1	C1	A2	T2	G2	C2	A3	T3	G3	C3	all
1	-	-	-	-	-	-	-	-	-	-	-	-	-
2	2	1	0	0	1	2	0	0	0	2	1	0	9	
3	1	2	1	1	2	1	1	1	1	1	2	1	15	

#Custom stop codon:
name	A1	T1	G1	C1	A2	T2	G2	C2	A3	T3	G3	C3	all
1	-	-	-	-	-	-	-	-	-	-	-	-	-
2	2	1	0	0	1	2	0	0	0	2	1	0	9	
3	1	2	1	1	2	1	1	1	1	1	2	1	15	
```  

### 2.21 `GFFSimplifier.py [GFF_FILE] [ITEM_1 (Optional parameter)] [ITEM_2 (Optional parameter)] ... [ITEM_n (Optional parameter)]`
       
**Function Description:** Simplify the content of the attributes in the GFF file, filter out unneeded information, in order to reduce the size of the GFF file. 

- **GFF_FILE: ** The GFF file path must point to a GFF3 format file, where attributes are separated by ";", and key-value pairs within the attributes are connected by "=".
- **ITEM_X: ** The attributes keys to be retained—since ID and Parent are commonly used, they need not be specified. Different keys should be provided as separate input parameters. 

**Usage scenario:** Simplifying partial information in the GFF file can reduce its size, facilitating subsequent analyses.             

**Notes: ** ID and Parent need not be specified; avoid duplicating any items, otherwise the generated file will contain redundant entries.          

**Generated File:** 
- `simp_<GFF_FILE>`(GFF file, simplified file).  

**Example:**

比如 `example/maize.gff3` The file contains part of the GFF annotation from the maize reference genome B73 RefGen_v4.   
```
###
3	gramene	gene	125560575	125561600	.	-	.	ID=gene:Zm00001d041518
3	gramene	mRNA	125560575	125561600	.	-	.	ID=transcript:Zm00001d041518_T001;Parent=gene:Zm00001d041518
3	gramene	exon	125560575	125561600	.	-	.	Parent=transcript:Zm00001d041518_T001
3	gramene	CDS	125560575	125561600	.	-	0	ID=CDS:Zm00001d041518_P001;Parent=transcript:Zm00001d041518_T001
###
...
NC_024460.2	RefSeq	CDS	40178	41023	.	-	0	ID=cds-ONM11916.1;Parent=rna-gnl|WGS:LPUQ|mrna.ZEAMMB73_Zm00001d001763;Dbxref=NCBI_GP:ONM11916.1;Name=ONM11916.1;gbkey=CDS;locus_tag=ZEAMMB73_Zm00001d001763;orig_transcript_id=gnl|WGS:LPUQ|mrna.ZEAMMB73_Zm00001d001763;product=putative methyltransferase;protein_id=ONM11916.1
NC_024460.2	RefSeq	gene	99801	117243	.	-	.	ID=gene-ZEAMMB73_Zm00001d001765;Name=ZEAMMB73_Zm00001d001765;gbkey=Gene;gene_biotype=protein_coding;locus_tag=ZEAMMB73_Zm00001d001765;old_locus_tag=GRMZM2G046590%2CGRMZM2G074530
```  
The content is a test excerpt, so it may differ from the actual downloaded file, but this does not affect the validity of the test. Execute the command:     
```bash
# Keep only ID and Parent in the attributes column. 
python GFFSimplifier.py example/maize.gff3
 
# In addition to ID and Parent, also retain chromosome in the attributes column.    
python GFFSimplifier.py example/maize.gff3 chromosome  

# Retain the attributes chromosome, country, ID, and Parent in the GFF file. 
python GFFSimplifier.py example/maize.gff3 chromosome country  
```  
即可完成简化: 
```
#Keep only ID and Parent in the attributes column.
#Simplified by https://github.com/shueho/BioDataTools.
###
3	gramene	gene	125560575	125561600	.	-	.	ID=gene:Zm00001d041518
3	gramene	mRNA	125560575	125561600	.	-	.	ID=transcript:Zm00001d041518_T001;Parent=gene:Zm00001d041518
3	gramene	exon	125560575	125561600	.	-	.	Parent=transcript:Zm00001d041518_T001
3	gramene	CDS	125560575	125561600	.	-	0	ID=CDS:Zm00001d041518_P001;Parent=transcript:Zm00001d041518_T001
###   
...
NC_024460.2	RefSeq	CDS	40178	41023	.	-	0	ID=cds-ONM11916.1;Parent=rna-gnl|WGS:LPUQ|mrna.ZEAMMB73_Zm00001d001763
NC_024460.2	RefSeq	gene	99801	117243	.	-	.	ID=gene-ZEAMMB73_Zm00001d001765

#In addition to ID and Parent, also retain chromosome in the attributes column. 
...

#Retain the attributes chromosome, country, ID, and Parent in the GFF file.
...
```  

### 2.22 `BaseSiteFeatureFinder.py [GFF_FILE] [LOC_FILE] [DISTANCE] [FEATURE (Optional parameter)]`
       
**Function Description:** Batch retrieve features adjacent to nucleotide sequences.  

- **GFF_FILE: ** The GFF file path must point to a GFF3 format file, where attributes are separated by ";".    
- **LOC_FILE: ** A table describing locus positions, containing three columns: locus name, chromosome name, and position on the chromosome. Note: There should be no header row, and the chromosome names must exactly match those in the GFF file.      
- **DISTANCE: ** The distance to extend outward from the base locus. If set to 0, it means searching whether the base is located within a certain feature, serving as a replacement for script 2.18.     
- **FEATURE: ** The feature type to be scanned. Default is "gene". Can choose one from "gene/mRNA/CDS/exon/..." or other feature types present in the GFF file. For details, refer to the GFF file.    

**Usage scenario:** After obtaining significantly associated SNP loci from GWAS or other analyses, search for candidate genes.               

**Notes: ** If FEATURE is not specified, genes will be scanned by default. If set to "mRNA", transcripts will be scanned. Make sure the spelling is correct.            

**Generated File:** 
- `dis_<DISTANCE>_<FEATURE>_<LOC_FILE>`(Table, with columns representing: locus name / chromosome / position / gene name / distance from locus to feature start / distance to feature end / relationship between gene and locus interval. The relationship can be Left, Right, To_include, or Be_include, indicating that the gene is to the left of the interval, to the right of the interval, spans the interval, or is within the interval, respectively.)

**Example:**

For example, the file `example/maize.gff3` contains part of the GFF annotation from the maize reference genome B73 RefGen_v4, consistent with the content in section 2.21, and `example/base_loc.txt` contains the locus information of interest:   
```
S1_4399947	1	4399947
S1_4399947	1	4399947
S1_44365387	1	44365387
S3_115984758	3	115984758
S3_125574288	3	125574288
S3_125574288	3	125574288
```  
The first column of the locus information is the locus name; simply set a unique value. Then proceed to execute:  
```bash
# Retrieve genes within 14,000 bp distance of significant loci.  
python BaseSiteFeatureFinder.py example/maize.gff3 example/base_loc.txt 14000    
 
# Retrieve mRNAs within 14,000 bp distance of significant loci.  
python BaseSiteFeatureFinder.py example/maize.gff3 example/base_loc.txt 14000 mRNA  

# Determine whether the locus is located within a gene. 
python BaseSiteFeatureFinder.py example/maize.gff3 example/base_loc.txt 0  

# Determine whether the locus is located within a CDS.  
python BaseSiteFeatureFinder.py example/maize.gff3 example/base_loc.txt 0 CDS  
```
The result file can then be generated: 
```
#Retrieve genes within 14,000 bp distance of significant loci: dis_14000_gene_base_loc.txt
site_name	site_chr	site_pos	gene_name	star_dis	end_dis	position
S1_4399947	1	4399947	gene:Zm00001d027399	-2365	-4493	Be_include
S1_4399947	1	4399947	gene:Zm00001d027399	-2365	-4493	Be_include
S1_44365387	1	44365387	,-	-	-	-
S3_115984758	3	115984758	,-	-	-	-
S3_125574288	3	125574288	gene:Zm00001d041518	13713	12688	Be_include
S3_125574288	3	125574288	gene:Zm00001d041519	10670	10005	Be_include
S3_125574288	3	125574288	gene:Zm00001d041518	13713	12688	Be_include
S3_125574288	3	125574288	gene:Zm00001d041519	10670	10005	Be_include 

#Retrieve mRNAs within 14,000 bp distance of significant loci: dis_14000_mRNA_base_loc.txt
site_name	site_chr	site_pos	gene_name	star_dis	end_dis	position
S1_4399947	1	4399947	transcript:Zm00001d027399_T001	-2365	-4493	Be_include
S1_4399947	1	4399947	transcript:Zm00001d027399_T002	-2716	-4493	Be_include
S1_4399947	1	4399947	transcript:Zm00001d027399_T003	-2720	-4383	Be_include
S1_4399947	1	4399947	transcript:Zm00001d027399_T001	-2365	-4493	Be_include
S1_4399947	1	4399947	transcript:Zm00001d027399_T002	-2716	-4493	Be_include
S1_4399947	1	4399947	transcript:Zm00001d027399_T003	-2720	-4383	Be_include
S1_44365387	1	44365387	,-	-	-	-
S3_115984758	3	115984758	,-	-	-	-
S3_125574288	3	125574288	transcript:Zm00001d041518_T001	13713	12688	Be_include
S3_125574288	3	125574288	transcript:Zm00001d041519_T001	10670	10005	Be_include
S3_125574288	3	125574288	transcript:Zm00001d041518_T001	13713	12688	Be_include
S3_125574288	3	125574288	transcript:Zm00001d041519_T001	10670	10005	Be_include 

#Determine whether the locus is located within a gene:  dis_0_gene_base_loc.txt
site_name	site_chr	site_pos	gene_name	star_dis	end_dis	position
S1_4399947	1	4399947	,-	-	-	-
S1_4399947	1	4399947	,-	-	-	-
S1_44365387	1	44365387	,-	-	-	-
S3_115984758	3	115984758	,-	-	-	-
S3_125574288	3	125574288	,-	-	-	-
S3_125574288	3	125574288	,-	-	-	-

#Determine whether the locus is located within a CDS:  dis_0_CDS_base_loc.txt
site_name	site_chr	site_pos	gene_name	star_dis	end_dis	position
S1_4399947	1	4399947	,-	-	-	-
S1_4399947	1	4399947	,-	-	-	-
S1_44365387	1	44365387	,-	-	-	-
S3_115984758	3	115984758	,-	-	-	-
S3_125574288	3	125574288	,-	-	-	-
S3_125574288	3	125574288	,-	-	-	-
```

### 2.23 `IntervalFeatureFinder.py [GFF_FILE] [LOC_FILE] [FEATURE (Optional parameter)]`
       
**Function Description:** Batch retrieve features within specified genomic intervals.

- **GFF_FILE: ** The GFF file path must point to a GFF3 format file, where attributes are separated by ";".  
- **LOC_FILE: ** A table describing genomic intervals, containing four columns: locus name, chromosome name, start position on the chromosome, and end position. Note: There should be no header row, and the chromosome names must exactly match those in the GFF file.     
- **FEATURE: ** The feature type to be scanned. Default is "gene". Can choose one from "gene/mRNA/CDS/exon/..." or other feature types present in the GFF file. For details, refer to the GFF file.  

**Usage scenario:** Search for candidate genes after obtaining significantly associated QTL regions from QTL mapping or other analyses. This can be considered an advanced version of scripts 2.18 and 2.22: when the third and fourth columns of the input position table are identical, it is equivalent to the implementation of 2.18; when the input intervals have equal lengths, it is equivalent to the implementation of 2.22.               

**Notes: ** If FEATURE is not specified, genes will be scanned by default. If set to "mRNA", transcripts will be scanned. Make sure the spelling is correct.             

**Generated File:** 
- `Inter_<FEATURE>_<LOC_FILE>`(Table, with columns representing: locus name / chromosome / interval start position / interval end position / gene name / feature start position / feature end position / relationship between gene and locus interval. The relationship can be Left, Right, To_include, or Be_include, indicating that the gene is to the left of the interval, to the right of the interval, spans the interval, or is within the interval, respectively.)

**Example:**

For example, the file `example/maize.gff3` contains part of the GFF annotation from the maize reference genome B73 RefGen_v4, consistent with the content in section 2.21, and `example/base_loc.txt` contains the interval information of interest:   
```
a	1	4385947	4413947
b	1	4399947	4399947
c	1	44351387	44379387
d	3	115970758	115998758
e	3	125560288	125588288
f	3	125574288	125574288
```  
The first column of the interval information is the interval name; simply set a unique value. Then proceed to execute:  
```bash
# Retrieve genes within the specified intervals. 
python IntervalFeatureFinder.py example/maize.gff3 example/base_loc.txt    
 
# Retrieve mRNAs within the specified intervals. 
python IntervalFeatureFinder.py example/maize.gff3 example/base_loc.txt mRNA  
``` 
The result file can then be generated:  
```
#Retrieve genes within the specified intervals: Inter_gene_base_loc.txt
site_name	site_chr	site_s	site_e	gene_name	gene_s	gene_e	position
a	1	4385947	4413947	gene:Zm00001d027399	4402312	4404440	Be_include
b	1	4399947	4399947	,-	-	-	-
c	1	44351387	44379387	,-	-	-	-
d	3	115970758	115998758	,-	-	-	-
e	3	125560288	125588288	gene:Zm00001d041518	125560575	125561600	Be_include
e	3	125560288	125588288	gene:Zm00001d041519	125563618	125564283	Be_include
f	3	125574288	125574288	,-	-	-	-
 
#Retrieve mRNAs within the specified intervals: Inter_mRNA_base_loc.txt 
site_name	site_chr	site_s	site_e	gene_name	mRNA_s	mRNA_e	position
a	1	4385947	4413947	transcript:Zm00001d027399_T001	4402312	4404440	Be_include
a	1	4385947	4413947	transcript:Zm00001d027399_T002	4402663	4404440	Be_include
a	1	4385947	4413947	transcript:Zm00001d027399_T003	4402667	4404330	Be_include
b	1	4399947	4399947	,-	-	-	-
c	1	44351387	44379387	,-	-	-	-
d	3	115970758	115998758	,-	-	-	-
e	3	125560288	125588288	transcript:Zm00001d041518_T001	125560575	125561600	Be_include
e	3	125560288	125588288	transcript:Zm00001d041519_T001	125563618	125564283	Be_include
f	3	125574288	125574288	,-	-	-	-
``` 

### 2.24 `ExtractFastaWithGene.py [FASTA_FILE] [LIST_FILE]`

**Function Description:** Given a list of gene IDs, this script can extract all corresponding transcripts/proteins/cDNA sequences of the genes from the full FASTA file and generate a sub-FASTA file.    

- **FASTA_FILE: ** A FASTA-formatted sequence file, i.e., a file containing all sequences, such as the genome-wide pep or cDNA sequences.  
- **LIST_FILE: ** A list of genes to be extracted. For example, for gene ID G001, all sequences starting with "G001_" will be extracted.   

**Usage scenario:** Given a list of known genes, retrieve all transcript/protein/cDNA sequences for each gene.  

**Generated File:** 
- `out_match_seq.fasta`(FASTA file).

**Example:**

For example, `example/pro.fasta` is the complete protein FASTA file:  
```
>Zm00001eb423440_P001
MPNGGGKRWLLLLPLSRYVEVDEQQGVQLFYYFVRSERDPYEDPLLLWLSGGPGCSGISG...
>Zm00001eb423440_P004
MPNGGGKRWLLLLPLSRWVLLLGSLQLPAVGGSGHVVTRMRGFDGPLPFYLETGYVEVDE...
...
>Zm00001eb400040_P001
MASLCMFTISSTPHVPQGCRRRCSDAVSSRPRSYLVCQSHLPSGPPASGGGGGGGGEEKT...
``` 
`example/list.txt` is the list of genes to be extracted:  
```
Zm00001eb423440
Zm00001eb413340
``` 
Execute the command: 
```bash
python ExtractFastaWithGene.py example/pro.fasta example/list.txt    
```    
The result file `out_match_seq.fasta` will then be generated: 
```
>Zm00001eb423440_P001
MPNGGGKRWLLLLPLSRYVEVDEQQGVQLFYYFVRSERDPYEDPLLLWLSGGPGCSGISG...
>Zm00001eb423440_P004
MPNGGGKRWLLLLPLSRWVLLLGSLQLPAVGGSGHVVTRMRGFDGPLPFYLETGYVEVDE...
...
>Zm00001eb413340_P004
MQQIISACKLPHTQRAAAFLPPRPSLRRLPVPGLDRPGGAPPPRRLVVRRRCQEENKQQQ...
``` 

### 2.25 `CorrespondingNucleotideProteinFasta.py [FASTA_N] [FASTA_P]`

**Function Description:** Map transcript sequences and protein sequences to a tabular file.      

- **FASTA_N: ** A FASTA-formatted nucleotide sequence file, containing cDNA or transcript sequences, with naming convention "gene_name_Txxx".
- **FASTA_P: ** A FASTA-formatted amino acid sequence file, containing protein sequence data, with naming convention "gene_name_Pxxx".

**Generated File:** 
- `out_match_seq.tab`(Table file, with columns: gene / transcript or protein ID / nucleotide sequence / amino acid sequence. Sequences that cannot be matched are marked as "-"). 

**Example:**

For example, `example/pro.fasta` is the complete protein FASTA file, with format consistent with section 2.25, and `example/cdna.fasta` is the cDNA sequence data:  
```
#example/pro.fasta
>Zm00001eb423440_P001
MPNGGGKRWLLLLPLSRYVEVDEQQGVQLFYYFVRSERDPYEDPLLLWLSGGPGCSGISG...
>Zm00001eb423440_P004
MPNGGGKRWLLLLPLSRWVLLLGSLQLPAVGGSGHVVTRMRGFDGPLPFYLETGYVEVDE...
...
>Zm00001eb400040_P001
MASLCMFTISSTPHVPQGCRRRCSDAVSSRPRSYLVCQSHLPSGPPASGGGGGGGGEEKT...

#example/pro.fasta
>Zm00001eb423440_T001
GTTTATTTCTCTATTTGGTGCTTGCATGCCAACACATCTGTTTTTATATATTTTTAGTGG...
>Zm00001eb423440_T004
ATAGGGACCGGAGTGGCATTTGACCAGCTGAAGTCAACAGGCATGCCGAACGGTGGCGGC...
...
>Zm00001eb181160_T001
ATATGGGAAATGTATTTTACTCTTCATGCTTTTCCCCTTCGTGCAAGCAAAGCTAAACAA...
``` 
Execute the command: 
```bash
python CorrespondingNucleotideProteinFasta.py example/cdna.fasta example/pro.fasta   
```   
The result file `out_match_seq.tab` will then be generated:  
```
Zm00001eb413340	Zm00001eb413340_X001	GCCTCAACGG...	MQQIISACK...
Zm00001eb181160	Zm00001eb181160_X001	ATATGGGAAA...	-
Zm00001eb413340	Zm00001eb413340_X004	GCCTCAACGG...	MQQIISACK...
...
```   

### 2.26 `BatchModificationSequence.py [FASTA_FILE] [FIX_SEQ] [NEW_SEQ]`

**Function Description:** Batch replace the sequence preceding a fixed sequence with a specified sequence.    

- **FASTA_FILE: ** A FASTA-formatted nucleotide sequence file, containing all sequences to be modified.  
- **FIX_SEQ: ** The fixed sequence.
- **NEW_SEQ: ** The sequence to replace with.   

**Usage scenario:** Modify the sequence preceding a fixed sequence to a specific sequence, ensuring that the sequence upstream of the fixed sequence is correctly set for proper translation (this may be the intended concept).

**Generated File:** 
- `modif_seq.tab`(Table file, with columns: sequence name / original sequence / start position of fixed sequence / end position of fixed sequence / sequence after replacement. If the fixed sequence is not found, the last three columns are marked as "-").

**Example:**

For example, `example/modif_seq.fasta` is the FASTA file containing the sequences to be modified:
```
>pAbAi-GSL4-67
NGCACGTAGACCATACGACGTACCAGATTAC...
>pAbAi-GSL4-24
CCCGTGAAGAACCATACGACGTACCAGATTA...
...
>pAbAi-GSL4-82
NCCCGATGACCATACGACGTACCAGATTACG...
``` 
Execute the command: 
```bash
# For example, replace the portion before the sequence ATACGACGTACCAGATTACGCTCATATG with ATGGAGTACCC.  
python BatchModificationSequence.py example/modif_seq.fasta ATACGACGTACCAGATTACGCTCATATG ATGGAGTACCC     

# Interestingly, if the last two parameters are set to a non-existent sequence, this script can effectively convert a FASTA file into a tabular format... After running, simply delete all columns except the first two!     
python BatchModificationSequence.py example/modif_seq.fasta - -
```  
The result file `modif_seq.tab` will then be generated:
```
#For example, replace the portion before the sequence ATACGACGTACCAGATTACGCTCATATG with ATGGAGTACCC.   
pAbAi-GSL4-67	NGCACGTAGACCATACGACGTA...	13	40	ATGGAGTACCCATACGACGTACC...
pAbAi-GSL4-24	CCCGTGAAGAACCATACGACGT...	14	41	ATGGAGTACCCATACGACGTACC...
pAbAi-GSL4-3	CATACGCACGTACCAGTATTAC...	-	-	-
...

#This script can be used to convert a FASTA file into a tabular file. After running, delete all columns except the first two!    
pAbAi-GSL4-67	NGCACGTAGACCATACGACGTA...	-	-	-
pAbAi-GSL4-24	CCCGTGAAGAACCATACGACGT...	-	-	-
pAbAi-GSL4-3	CATACGCACGTACCAGTATTAC...	-	-	-
...
```      

### 2.27 `TableToMultipleFasta.py [TABLE_FILE]`

**Function Description:** Convert the table into a FASTA file by rows, with multiple sequences from each row placed in the same file.      

- **TABLE_FILE: ** A table file, where each row will generate a separate FASTA file. Sequences in the same row are split into the same FASTA file, and the first column contains the FASTA file name.  

**Usage scenario:** Quickly split sequences from multiple sources (e.g., different species, transcripts, samples, or gene families) of the same sequence type (gene or amino acid) for downstream analysis. For example, if you want to rapidly align each FASTA file, you can use the CLUSTALW command line to batch align all FASTA files in the output directory.     

**Notes: ** The first column of the table specifies the name of the split FASTA file; names must not be duplicated!!! File names must follow system naming conventions and must not contain special characters.            

**Generated File:** 
- `out_fastas`(Directory containing multiple FASTA files, with file names corresponding to the entries in the first column of the table.)  

**Example:**

For example, `example/fasta_per_row.txt` is the required file: 
```
Work-001	MEYPYDVPDYAHMTSLYKKVGRGQ...	MAANSTATKHAFKRILTSLI...		
Work-002	MEYPYDVPDYAHMTSLYKKVGSRP...	CRPCTALIPCRQQQRWRRGY...	WRRGYRRPISTSTSPR...	
Work-003	MEYPYDVPDYAHMTSLYKKVGSSP...			
...
``` 
Execute the command: 
```bash
python TableToMultipleFasta.py example/fasta_per_row.txt
```    
Multiple FASTA files will then be generated: 
```
out_fastas/
├── Work-001.fa  
├── Work-002.fa
├── ...
└── Work-005.fa

#Work-001.fa
>Work-001_1
MEYPYDVPDYAHMTSLYKKVGRGQ...
>Work-001_2
MAANSTATKHAFKRILTSLI...
``` 

### 2.28 `MultipleFastaToTable.py [FASTA_DIR]`

**Function Description:** Convert multiple FASTA files into a single table, with sequences from the same file placed in the same row (reverse operation of 2.27).      

- **FASTA_DIR: ** Folder path containing the FASTA files to be merged.  

**Usage scenario:** Quickly merge sequences from multiple sources (e.g., different species, transcripts, samples, or gene families) of the same sequence type (gene or amino acid) for downstream analysis.    

**Notes: ** In the generated table, each sequence retains its original name. To convert to pure sequences, open the file in Excel and replace `*~~` with blank (note: there must be two tildes `~~`). Ensure that there are no other files in the folder.            

**Generated File:** 
- `merge.tab`(Table file, where the first column is the FASTA filename, and subsequent columns contain all sequences from that file.)  

**Example:**

There are multiple FASTA files:  
```
example/
├── Work-001.fa  
├── Work-002.fa
├── ...
└── Work-005.fa

#Work-001.fa
>Work-001_1
MEYPYDVPDYAHMTSLYKKVGRGQ...
>Work-001_2
MAANSTATKHAFKRILTSLI...
``` 
You can execute: 
```bash
python MultipleFastaToTable.py example/mul_fastas
```  
The result file `merge.tab` will then be generated:   
```
Work-001	MEYPYDVPDYAHMTSLYKKVGRGQ...	MAANSTATKHAFKRILTSLI...		
Work-002	MEYPYDVPDYAHMTSLYKKVGSRP...	CRPCTALIPCRQQQRWRRGY...	WRRGYRRPISTSTSPR...	
Work-003	MEYPYDVPDYAHMTSLYKKVGSSP...			
...
```
It can be seen that this script is the reverse operation of 2.28!        
   
### 2.29 `AlignConsistencyChecker.py [FASTA_DIR]`

**Function Description:** Align the sequences from multiple FASTA files, compare them site by site, and identify positions where all sequences are identical.      

- **FASTA_DIR: ** Folder path containing multiple aligned FASTA files to be compared. 

**Notes: ** The generated file must be opened in Excel, and the text font should be changed to a monospaced font such as SimSun. Be sure to use alignment results that have already been aligned! The folder must not contain any other files.            

**Generated File:** 
- `aln_res.txt`(Text file; recommended to open in Excel and adjust the font to SimSun for viewing. Different alignment results are separated by blank lines. Lines marked "**ALN**" show the comparison result: identical sites are denoted by "*", and non-identical sites by "_".)  

**Example:**

There are multiple aligned FASTA files:     
```
example/
├── Work-001.fa  
├── Work-002.fa
└── Work-003.fa

#Work-001.fa
>Work-001_1
------------------------------------------------------------...
>Work-001_2
MAANSTATKHAFKRILTSLIKPGGGEYGKFFSLPALNDPRIDKLPYSIRVLLESAIRHCD...
>Work-001_3
MAANSTAT--AFKRILTSLIKPKGGEYGKFFSLPALNDPRIDKLPYSIRVLLESAIRHCD...
``` 
You can execute: 
```bash
python AlignConsistencyChecker.py example/aln_fasta
``` 
The result file `aln_res.txt` will then be generated:    
```
Work-001.fa
Work-001_1	------------------------------------------------------------...
Work-001_2	MAANSTATKHAFKRILTSLIKPGGGEYGKFFSLPALNDPRIDKLPYSIRVLLESAIRHCD...
Work-001_3	MAANSTAT--AFKRILTSLIKPKGGEYGKFFSLPALNDPRIDKLPYSIRVLLESAIRHCD...
**ALN**	_________________________________________________________...
Work-002.fa
...		
```    

### 2.30 `MergeMultipleFasta.py [FASTA_1] [FASTA_2] ... [FASTA_n]`

**Function Description:** Merge multiple FASTA files and remove redundant (duplicate) sequences.      

- **FASTA_1/2/.../n: ** FASTA file path, at least one parameter must be specified.  

**Usage scenario:** 1.When only one FASTA file is specified, it is equivalent to removing redundancy from the sequences within that single file; 2.When multiple FASTA files are specified, not only are sequences deduplicated, but a correspondence table of sequence IDs across different FASTA files is also generated.  

**Notes: ** At least one parameter must be specified. When only one parameter is provided, do not confuse this with script 1.02: script 1.02 renumbers sequences (assigning different IDs regardless of sequence identity), whereas this script consolidates identical sequences under a single ID. If duplicate IDs exist in the original file (regardless of whether the sequences are identical), only the last occurrence is retained.          

**Generated File:** 
- `merge.fasta`(FASTA file).  
- `GeneIDMatch.table`(Table file, showing the ID correspondence of sequences across different FASTA files.)   

**Example:**

There are multiple aligned FASTA files:  
```
example/merge_fasta/
├── File1.fasta  
├── File2.fasta
└── File3.fasta
``` 
You can execute: 
```bash
# Specify only one parameter to remove redundancy from a single file.   
python MergeMultipleFasta.py example/merge_fasta/File1.fasta     

# Specify two parameters to compare sequence IDs between two files.  
python MergeMultipleFasta.py example/merge_fasta/File1.fasta example/merge_fasta/File2.fasta

# Specify three parameters to compare sequence IDs among three files.
python MergeMultipleFasta.py example/merge_fasta/File1.fasta example/merge_fasta/File2.fasta example/merge_fasta/File3.fasta
```     
The merged result file `merge.fasta` and the redundancy summary file `GeneIDMatch.table` will then be generated, using the merging of three FASTA files as an example:   
```
#merge.fasta
>N_0000000001 
CCAAAAAACCCCC
>N_0000000002 
TTAAAGGG
>N_0000000003 
ATCGGCTA
>N_0000000004 
AGGAACCGG
>N_0000000005 
ATGGATTTTTAACG
>N_0000000006 
CCGGTTAAAAAA
>N_0000000007 
CCGAATTTGGGC
>N_0000000008 
AATTGGCAATTGGC

#GeneIDMatch.table
Nid	example/merge_fasta/File1.fasta	example/merge_fasta/File2.fasta	example/merge_fasta/File3.fasta
N_0000000001 	-	UniSeq	-
N_0000000002 	Seq	Seq	-
N_0000000003 	SameNameSameSeq	SameNameSameSeq	SameNameSameSeq
N_0000000004 	-	-	SameNameDifSeq
N_0000000005 	SameNameDifSeq	-	-
N_0000000006 	UniSeq	-	-
N_0000000007 	DifNameSameSeq1	DifNameSameSeq2	-
N_0000000008 	Seq2/Seq3	-	-
```  

### 2.31 `MitosToGFF.py [MITOS_FILE]`

**Function Description:** Convert Mitos annotation results into GFF file format.    

- **MITOS_FILE: ** The .mitos file generated by Mitos.   
        
**Generated File:** 
- `result_mitos.gff`(GFF file).

**Example:**

For example, `example/result.mitos` is the annotation result generated by the MITOS software: 
```
test	rep_origin	OL	mitfi	34	62	-1	3.70E-05	24.8	-	None	.	.	(((((((((...........)))))))))
test	rep_origin	OH	mitos	244	898	1	13308146.4	.	-	-	.	.	.
...
test	tRNA	trnE	mitfi	16617	16685	-1	5.90E-10	60.2	TTC	29	.	.	(((((((..((((....)))).(((((.......)))))....(((((........)))))))))))).
``` 
Execute the command: 
```bash
python MitosToGFF.py example/result.mitos
```  
The result file `result_mitos.gff` will then be generated:   
```
test	mitfi	rep_origin	35	63	.	-	.	ID=OL
test	mitos	rep_origin	245	899	.	+	.	ID=OH
test	mitfi	tRNA	1155	1222	.	+	.	ID=trnF-GAA
test	mitfi	rRNA	1222	2188	.	+	.	ID=rrnS
...
test	mitos	gene	16095	16616	.	-	.	ID=nad6
test	mitfi	tRNA	16618	16686	.	-	.	ID=trnE-TTC		
```  
  
### 2.32 `MitosToFasta.py [MITOS_FILE] [FASTA_FILE]`

**Function Description:** Convert Mitos annotation results into GFF file format.    

- **MITOS_FILE: ** The .mitos file generated by Mitos.  
- **FASTA_FILE: ** The FASTA file imported into the Mitos program/web server, i.e., the file used for genome annotation.     
        
**Generated File:** 
- `result_mitos.fasta`(FASTA file, where tRNA sequences have their anticodon and secondary structure annotated in the sequence header.)

**Example:**

For example, `example/result.mitos` is the annotation result generated by the MITOS software: 
```
test	rep_origin	OL	mitfi	34	62	-1	3.70E-05	24.8	-	None	.	.	(((((((((...........)))))))))
test	rep_origin	OH	mitos	244	898	1	13308146.4	.	-	-	.	.	.
...
test	tRNA	trnE	mitfi	16617	16685	-1	5.90E-10	60.2	TTC	29	.	.	(((((((..((((....)))).(((((.......)))))....(((((........)))))))))))).
``` 
The corresponding FASTA sequence file is `example/mitos.fasta`. Execute the command: 
```bash
python MitosToFasta.py example/result.mitos example/mitos.fasta  
```    
The sequence file for each feature, `result_mitos.fasta`, will then be generated: 
```
>OL
TACCCCCCCTGGGGGGGAAAGGGGGGGTA

>OH
TCCCCCCCCAAGGCACCTAATCTATGAATGGTCACAGGACATA...
...

>nad6
ATGACTTATTTTGTGATTTTTTTGGGAGTTAGTTTTGCATTAGG...

>trnE-TTC (((((((..((((....)))).(((((.......)))))....(((((........)))))))))))).
GTTCCCGTAGTTGAGAACAACGATGGCTTTTCAAGCCGTAGTCCTTGGAGTTTAGGCCAAGCGGGAATA	
```  

### 2.33 `SsToFold.py [SS_FILE]`

**Function Description:** Convert the secondary structure file (.ss) generated by tRNAscan-SE into the fold format supported by RNAplot (same format as files generated by RNAfold).     

Convert the file:    
```    
NC_020585.1.trna1 (1155-1222)	Length: 68 bp
Type: Phe	Anticodon: GAA at 32-34 (1186-1188)	Score: 73.8
         *    |    *    |    *    |    *    |    *    |    *    |    *  
Seq: GCCCACATAGCTTAACCCAAAGCATGACACTGAAGATGTTAAGATGGTACCCATACTACCTGTGGACA
Str: >.>>>>>..>>>>......<<<<.>>>>>.......<<<<<....>>>>.......<<<<<<<<<.<.

NC_020585.1.trna2 (2188-2258)	Length: 71 bp
Type: Val	Anticodon: TAC at 33-35 (2220-2222)	Score: 81.3
         *    |    *    |    *    |    *    |    *    |    *    |    *    |
Seq: CAAGGCGTAGCTATAAACCAAAGCACTCAGCTTACACCTGAAAGATGCCTTCAAAgaTAAGGTCGCCTTGA
Str: >>>>>>>..>>>.........<<<..>>>>.......<<<<.....>>>>.........<<<<<<<<<<<.

NC_020585.1.trna3 (3876-3949)	Length: 74 bp
Type: Leu	Anticodon: TAA at 36-38 (3911-3913)	Score: 111.8
         *    |    *    |    *    |    *    |    *    |    *    |    *    |   
Seq: GCTAGCGTGGCAGAGCTcGGTaAATGCAAAAGGCTTAAGCCCTTTCCCCAGAGGTTCAAATCCTCTCCCTAGCT
Str: >>>>>.>..>>>............<<<.>>>>>.......<<<<<....>>>>>.......<<<<<<.<<<<<.

``` 
into:    
```
>trnF-1155-1222
GCCCACATAGCTTAACCCAAAGCATGACACTGAAGATGTTAAGATGGTACCCATACTACCTGTGGACA
(.(((((..((((......)))).(((((.......)))))....((((.......))))))))).).
>trnV-2188-2258
CAAGGCGTAGCTATAAACCAAAGCACTCAGCTTACACCTGAAAGATGCCTTCAAAgaTAAGGTCGCCTTGA
(((((((..(((.........)))..((((.......)))).....((((.........))))))))))).
>trnL1-3876-3949
GCTAGCGTGGCAGAGCTcGGTaAATGCAAAAGGCTTAAGCCCTTTCCCCAGAGGTTCAAATCCTCTCCCTAGCT
(((((.(..(((............))).(((((.......)))))....(((((.......)))))).))))).
>trnI-4934-5004
GGAAGCGTGCCTGAATAAAAGGACCACTATGATAAAGTGGACATAGAGGTAAAacAATCCTCTCGCCTCCT
(((.(((..(((.......))).(((((.......)))))....(((((.........)))))))).))).
```
Note that this script converts amino acid three-letter abbreviations to single-letter abbreviations.   

- **SS_FILE: ** The .ss file generated by tRNAscan-SE.  

**Video tutorial:** https://www.bilibili.com/video/BV1fwDjYVEx9/  
        
**Generated File:** 
- `plot.fold`(File format consistent with that generated by RNAfold, compatible with RNAplot for batch plotting. Each sequence contains three lines: the first line is the sequence name, the second line is the nucleotide sequence, and the third line is the secondary structure notation.) 

**Example:**

```bash
python SsToFold.py example/trnascanse.ss  

#Subsequently, the RNAplot package can be used to draw the secondary structure diagram of tRNA.  
#RNAplot -f svg plot.fold    

#Organize all SVG files into a single file, which can be beautified using code 4.03. 
```     

### 2.34 `RSCUPlot.R`

**Function Description:** Obtain the codon preference of protein-coding genes and plot the RSCU bar chart.   

**Notes: ** This R script provides data statistics and plotting functions and cannot be directly invoked via the command line.

**Video tutorial:** https://www.bilibili.com/video/BV1GQnWztEzF/    

**Generated File:** 
- `01-sequences.csv`(Table file containing sequences of each protein-coding gene and information on start and stop codons.)  
- `02-Codon_occurrence_in_all_gene.csv` (Table file containing codon usage frequency and relative frequency for all protein-coding genes.) 
- `03-Codon_occurrence_matrix.csv`(Table file, codon preference matrix.)
- `04-RSCU_matrix.csv` (Table file, RSCU matrix.)
- `05-<GENE>_RSCU.csv`(Table file containing RSCU values and codon usage frequency for the specified gene.)
- `06-<GENE>_RSCU_plot_file.csv` (Table file containing raw data for custom plotting.)
- `07-<GENE>_RSCU_plot.pdf`(Images drawn using default parameters.)

**Example:**

For example, `example/pcgs.fa` is the extracted CDS sequences of protein-coding genes.   
```
>nad1
ATGACCCCACTAACCCCAATAAACCTCACAATCATAACTTTATCTTACATAATCCCAAT...
...
>nad6
ATGACTTATTTTGTGATTTTTTTGGGAGTTAGTTTTGCATTAGGGGTTTTAGCTGTAGC...
```
Additionally, the script has been downloaded locally. Assuming the script is placed at `xxx/xxx/RSCUPlot.R`, open R or RStudio and execute the command:   
```bash
source("xxx/xxx/RSCUPlot.R")
# Note: Be sure to specify the correct path in the source() function!

# If the working directory has already been set to the folder containing the script, you can run directly: 
# source("RSCUPlot.R")
``` 
If this is the first time running, several R packages may need to be downloaded. After loading is complete, you can use the following code or functions:   
```
# Set the path to the protein-coding genes.
pcg = "example/pcgs.fa"

# Set the codon table. It is recommended to refer to https://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi?chapter=tgencodes and select the appropriate codon table.
# The example selects the second codon table, so enter the number 2:
codonTable = 2

# Run the function to generate 7 result files, including the RSCU bar chart for all protein-coding genes collectively.  
df = main_fun(pcg,codonTable)

# If you want to export the RSCU bar chart for a specific gene, you can specify the gene parameter.
# df = main_fun(pcg,codonTable,gene="nad6")
# Note that by default, the results for all protein-coding genes are output, i.e., gene="Total".

# If you are not satisfied with the exported image dimensions, you can call: 
# plot_rscu(rscu_d, out_path,h1=0.6,h2=6,yLim=6.2)
# where rscu_d is the data frame used for plotting, i.e., the returned value df from the main_fun function;
# out_path is the output file path;
# h1 controls the vertical spacing between codon rectangles; if the rectangles overlap, you can appropriately increase this value;
# h2 is the height of the output image; note that when increasing h2, you should also adjust the h1 parameter accordingly to maintain visual appeal;
# yLim sets the upper limit of the bar chart. Except for the 5th codon set, the sum of RSCU values for each amino acid does not exceed 6, so 6.2 is appropriate. For the 5th codon set, the amino acid Ser has 8 codons, so a value around 8 is suitable;
# Based on the author's testing, h1=0.6 and h2=6 produce a well-proportioned flat-shaped graph, while h1=0.2 and h2=12 generate a nearly square-shaped graph.
# Example of custom plotting: plot_rscu(df, "111.pdf", 0.1, 24, 8.2)
# After plotting, it is recommended to use PDF editing software to reduce the vertical distance between codon labels and the bars.
# If the default appearance is not satisfactory, feel free to modify the function!	
```

### 2.35 `splitGB.py [GB_FILE]`

**Function Description:** Split a multi-sequence GenBank file.   

- **GB_FILE: ** The GenBank file that needs to be split.   

**Usage scenario:** GB files downloaded using the NCBI Batch Entrez tool (https://www.ncbi.nlm.nih.gov/sites/batchentrez) are multi-sequence GB files; this script can be used if you need to split them.  
        
**Generated File:** 

- `gb_output/xx.gb`(Each sequence will generate a separate GB file).

**Example:**

For example, the file `example/sequence.gb` contains many sequences:
```
LOCUS       NC_036066              16785 bp    DNA     circular INV 03-APR-2023
DEFINITION  Dorcadia ioffi mitochondrion, complete genome.
ACCESSION   
VERSION     NC_036066.1
DBLINK      BioProject: PRJNA927338
...
 20821 aataacgatt gtattatatt ccctattata taatacaatt tattataaaa ttaactatct
    20881 aatatatccc gtgtaattaa ttattttaat a
//

LOCUS       MW310242               18902 bp    DNA     circular INV 24-JUL-2021
DEFINITION  Xenopsylla cheopis mitochondrion, complete genome.
ACCESSION   MW310242
VERSION     MW310242.1
...
//
```
Execute the command: 

```bash
python splitGB.py example/sequence.gb
```     
This will generate the output folder `gb_output`: 
```
codemlnull/
├── Ctenocephalides_felis_felis_MW420044.gb  
├── OG0005964.fa.nuc.ctlDorcadia_ioffi_VERSION.gb
├── Eukaryota_Metazoa_Ecdysozoa_Arthropoda_Hexapoda_Insecta_NC_040301.gb
├── Hystrichopsylla_weida_qinlingensis_NC_042380.gb
└── Xenopsylla_cheopis_MW310242.gb
```   

## 3. Gadget: Some general text processing and analysis tools, as well as code related to enrichment annotation analysis.

### 3.01 `MergeTable.py`

***Graphical interface tool for merging tables***

**Function Description:** When merging multiple tables, a corresponding join operation can be performed based on their first column data.  

**Parameter Description:** No parameter configuration is required. Import all the tables that need to be merged based on their first column one by one, and use the corresponding function to merge them by the first column content with a single click. 

**Notes: ** Only supports graphical systems. Tables can be either tab-separated or comma-separated; if a table contains tabs, it will be treated as tab-separated.    

**Generated File:** 

- `merge.txt`(Merged table). 
- `error.log`(Log file generated if the merge fails).

**Example:**

In a system with a graphical interface, run the following command to open the graphical interface:   
```bash
python MergeTable.py
``` 
Click "Open" to add tables that need to be merged, and click "Merge!" to start the merging process. If an error occurs during merging, an error message will be displayed.    
```
#There are some examples in the example folder.

##Case 1: Normal merge
#sample1.tsv
ID	Name	Age
1	Alice	25
2	Bob	30
3	Charlie	35

#sample2.tsv
Nun	Height	Weight
1	165	60
2	175	75
3	160	55

#After merging is completed: 
fid	Name	Age	Height	Weight
2	Bob	30	175	75
1	Alice	25	165	60
3	Charlie	35	160	55
#It can be seen that regardless of what the identifiers in the first column are, they are used as the reference for merging.

##Case 2: Merging with missing values
#sample3.tsv
ID	Feature1	Feature2
1	Value1	ccc
3	kkk	ValueC
A	Value2	ValueB

#Input the three files simultaneously: 
fid	Name	Age	Height	Weight	Feature1	Feature2
A	-	-	-	-	Value2	ValueB
1	Alice	25	165	60	Value1	ccc
2	Bob	30	175	75	-	-
3	Charlie	35	160	55	kkk	ValueC
# It can be seen that regardless of the input file order, tables with consistent content can be obtained, although the corresponding columns may appear in different orders.

# The example only shows tab-separated files, but comma-separated tables are also supported. Tab-separated format is recommended.  
# After running, if "finish!" is displayed in the terminal, the process was successful.  
# If "xxx can not merge" is displayed, the table merging has failed; please check whether all tables are in plain text format (can be opened with a text editor like Notepad). 
```

### 3.02 `VLookup.py [KEY_FILE] [MAP_FILE] [KEY_LOC] [VALUE_LOC] [SEP (Optional parameter)]`

**Function Description:** Python implementation of the vlookup function. The positions of the key and value can be customized.

- **KEY_FILE:** A file containing the column of values to be looked up.  
- **MAP_FILE:** The table in which to perform the lookup, which must have at least two columns, one being the key and the other the value.  
- **KEY_LOC:** The column number of the key in the MAP_FILE table. For example, if the key is in the first column, enter 1.  
- **VALUE_LOC:** The column number of the value in the MAP_FILE table. For example, if the value is in the first column, enter 1.  
- **SEP:** The separator used in the MAP file. The default is tab "\t". For comma-separated files, use ",". Note that the quotes should be in English (half-width).   

**Usage scenario:** Extract annotation information for certain genes from the full annotation table. Note that this can only extract one column of content.         

**Generated File:** 
- `map_<map file name>`（TABLE file）。

**Example:**

In the example, there is a list containing keys, `key.txt`:
```
ProteinA
ProteinB
ProteinC
```
Additionally, there is a file `map.txt` that includes both keys and values:  
```
GeneA	Location1	ProteinA
GeneD	Location4	ProteinD
GeneC	Location3	ProteinC
```
It is observed that the key is located in the 3rd column of the index file, so KEY_LOC is set to 3. If the desired value is from the "Gene" column, set VALUE_LOC to 1; if from the "Position" column, set VALUE_LOC to 2. Since the map file is a tab-separated table, SEP is set to the default value. Therefore, run: 
```bash
#Extract the Gene column
python VLookup.py example/key.txt example/map.txt 3 1
``` 
Finally, the result file will be generated:  
```
ProteinA	GeneA
ProteinB	-
ProteinC	GeneC
```

### 3.03 `SumByGroup.py [MAP_FILE] [MATRIX_FILE] [KEY_COL_ID] [VALUE_COL_ID]`

**Function Description:** 分组求和的进阶版。

- **MAP_FILE:** During data processing, the table used must contain a grouping column and a column listing all members within each group. The relationship between groups and members can be one-to-one, one-to-many, many-to-one, or many-to-many. Groups and their members are separated by commas. For example: "A,B" means that both group A and group B contain the same member "a"; whereas "A a,b" indicates that group A contains members "a" and "b".
- **MATRIX_FILE:** An abundance table or similar matrix. Ensure that the matrix file includes a header row, and the elements in the first column must match the member values (not the groups) in the MAP_FILE. For example, in a gene abundance matrix, the first column typically contains gene names, which belong to different gene families, and the matrix also includes abundance data columns for various samples.
- **KEY_COL_ID:** In the MAP file, specify the column number (index) where the group names are located. Here, 0 represents the first column, 1 the second column, and so on. This indicates the position of the group information in each row.
- **VALUE_COL_ID:** In the MAP file, specify the column number (index) where the member names are located. Here, 0 represents the first column, 1 the second column, and so on. This indicates the position of the member information in each row.

**Usage scenario:** When processing data, suppose you have a map table that records the relationship between each gene and its corresponding gene family, and you also have a matrix table listing the abundance data for each gene. In this case, you need to combine these two tables to calculate the total abundance for each gene family. The same approach applies to species abundance tables.                 

**Notes: ** Make sure that both the map table and the matrix table contain header rows to correctly identify column information. Additionally, when calculating relative abundance, the total count value from "all.count" should be used as the denominator for calculating the abundance of each sequence.

**Generated File:** 
- `out.count` (TABLE file, group summation table).  
- `all.count` (TABLE file, total summation table).

**Example:**

For example, the `example` directory contains the map file and matrix file: 
```
#map.txt
value	key
a1	A
a2	A
b1,d1	B,D
c1	C
c2	C
e1	E

#matrix.txt
value	a	b	c	d
a1	123	5	6	100
a2	1	1	0	0.555
b1	0.1	0.2	0.3	0.4
c1	0	2	1.1	4.1
d1	0	0	1.2	1.0
```
It is observed that the key column is in the second column (index 1), and the value column is in the first column (index 0). Execute the command: 
```bash
python SumByGroup.py example/map.txt example/matrix.txt 1 0
```
Finally, the result files will be generated:   
```
#out.count
value	a	b	c	d
A	124.0	6.0	6.0	100.555
B	0.1	0.2	1.5	1.4
D	0.1	0.2	1.5	1.4
C	0.0	2.0	1.1	4.1
E	0.0	0.0	0.0	0.0

#all.count
value	a	b	c	d
all_gene	124.1	8.2	8.6	106.055
```
Dividing the values in each column of the matrix result (absolute abundance) by the total count value yields the relative abundance.

### 3.04 `CountByGroup.py [-h] [-a MAPA] [-b MAPB] [-k KEA] [-K KEB] [-v VAA] [-V VAB] [-s SEA] [-S SEB] [--seka SEKA] [--sekb SEKB] [--seva SEVA] [--sevb SEVB] [-n HEADA] [-N HEADB]`
         
**Function Description:** For a data structure with a three-level mapping relationship A-B-C, the task is to find all elements in layer A that are associated with elements in layer C, and to count the number of these elements.

**Parameter Description:** 

```bash
options:
  -h, --help            show this help message and exit
  -a MAPA, --mapa MAPA  The path of the large group map. 
  -b MAPB, --mapb MAPB  The path of the small group map.
  -k KEA, --kea KEA     The column number of the large group key. default=0 (0 starts counting).
  -K KEB, --keb KEB     The column number of the small group key. default=0 (0 starts counting).
  -v VAA, --vaa VAA     The column number of the large group value. default=1 (0 starts counting).
  -V VAB, --vab VAB     The column number of the small group value. default=1 (0 starts counting).
  -s SEA, --sea SEA     The key-value separator of the large group value. default="\t"
  -S SEB, --seb SEB     The key-value separator of the small group value. default="\t"
  --seka SEKA           The key separator of the large group value. default=","
  --sekb SEKB           The key separator of the small group value. default=","
  --seva SEVA           The value separator of the large group value. default=","
  --sevb SEVB           The value separator of the small group value. default=","
  -n HEADA, --heada HEADA
                        The Number of excluded rows of the large group value. default=0 (0 starts counting).
  -N HEADB, --headb HEADB
                        The Number of excluded rows of the small group value. default=0 (0 starts counting).        
```

**Usage scenario:** For example, in a biological process involving three GO terms, there are overlapping genes among these terms. You want to count the total number of unique genes associated with the biological process (after removing duplicates).

**Notes: ** Parameters -a and -b are required; all other parameters have default values!

**Generated File:** 
- `count_Map.txt`(table file).

**Example:**

For example, the `example` directory contains a large map file and a small map file:
```
#map.txt
value	key
a1	A
a2	A
b1,d1	B,D
c1	C
c2	C
e1	E

#map2.txt
a1	i1,i2,i3
a2	i2,i4
b1	i5,i6
b2	i1
c1,a1	i3,i5
```
It is observed that in the large table, the key column is in the second column (corresponding to k=1), and the value column is in the first column (corresponding to v=0); in the small table, the key column is in the first column (corresponding to K=0, default), and the value column is in the second column (corresponding to V=1, default). The large table contains one header row (corresponding to n=1). Execute the command:
```bash
python CountByGroup.py -a example/map.txt -b example/map2.txt -n 1 -k 1 -v 0
```
The result file will then be generated:   
```
A	5	i2;i3;i5;i1;i4
B	2	i5;i6
D	2	i5;i6
C	2	i5;i3
E	0	
```

### 3.05 `FastaSplitter.py [FASTA_FILE_PATH] [Number_of_split_files]`
       
**Function Description:** For a FASTA file containing a large number of sequences, it can be split into multiple smaller FASTA files based on the number of sequences.

- **FASTA_FILE_PATH:** The path to the FASTA file to be split.  
- **Number_of_split_files:** The number of sequences each resulting file will contain after splitting.

**Usage scenario:** For example, when performing online KEGG annotation, the KEGG service may have limitations on the number of sequences that can be uploaded at once. By pre-splitting a large FASTA file, you can ensure compliance with upload requirements and successfully complete the annotation task.

**Generated File:** 
- `<split_file_number>_<original_FASTA_file>` (multiple FASTA files).   

**Example:**

Run the following command to split the FASTA file `example/text.fa` containing 7 sequences into 3 files with 2 sequences each (the last file will have only one sequence if not evenly divisible).
```bash
python FastaSplitter.py example/text.fa 2
```
Three FASTA files will then be generated.

### 3.06 `KeggAnnotationParser.py [KEG_FILE]`
   
**Function Description:** Parse KEG files. This tool can parse .keg annotation files downloaded from the KEGG website, and is useful for enrichment analysis or manually constructing background gene sets for gene annotation.

- **KEG_FILE: ** KEG files downloaded from the KEGG database, such as the universal ko00001.keg or the human-specific hsa00001.keg.

**Usage scenario:** Using this script, you can obtain a simplified table of pathway IDs for each KO or each species in the KEGG database, which can be used: ① to parse KEGG annotation results obtained from the KEGG online annotation website; ② to parse KEGG pathway databases for model organisms or general annotation tables.
                 
> You can click the link to download the universal KEG file: https://www.kegg.jp/kegg-bin/download_htext?htext=ko00001&format=htext&filedir=  
> Replace "ko" in htext=ko00001 in the above URL with a species abbreviation to download the KEG file for a specific organism. For example, replacing it with "hsa" (https://www.kegg.jp/kegg-bin/download_htext?htext=hsa00001&format=htext&filedir=) gives the human KEG file.  
> You can find species abbreviations at: https://www.genome.jp/kegg/catalog/org_list.html. For instance, the abbreviation for mouse is "mmu".

**Notes: ** The example folder contains human and universal keg files downloaded from the KEGG website. To ensure the database is up to date, manual download is recommended.  

**Generated Files:**  
- `output_<your_keg_filename>` (table file)  
- `<your_keg_prefix (species abbreviation)>_map.txt` (table file; if you need to perform KEGG enrichment analysis, you can use Excel's VLOOKUP function with this file to complete the background gene set)

**Example:**

```bash
# For example, parsing the universal keg file: 
python KeggAnnotationParser.py example/ko00001.keg

# For example, parsing a human KEG file:
python KeggAnnotationParser.py example/hsa00001.keg
```
The result file will be generated: 
```
##Parsing a generic KEG file:
#output_ko00001.txt
A-PATH	LEVEL-A	B-PATH	LEVEL-B	ID (C-PATH)	LEVEL-C	D-KO
09100	Metabolism	09101	Carbohydrate metabolism	ko00010	Glycolysis / Gluconeogenesis	K00844  HK; hexokinase [EC:2.7.1.1]
09100	Metabolism	09101	Carbohydrate metabolism	ko00010	Glycolysis / Gluconeogenesis	K12407  GCK; glucokinase [EC:2.7.1.2]
...

#ko_map.txt
ko	Level-A	Level-B	Level-C
ko02026	Cellular Processes	Cellular community - prokaryotes	Biofilm formation - Escherichia coli
ko00522	Metabolism	Metabolism of terpenoids and polyketides	Biosynthesis of 12-, 14- and 16-membered macrolides
ko04061	Environmental Information Processing	Signaling molecules and interaction	Viral protein interaction with cytokine and cytokine receptor
...

##Parsing a human KEG file: 
#output_hsa00001.txt
A-PATH	LEVEL-A	B-PATH	LEVEL-B	ID (C-PATH)	LEVEL-C	D-GENES	D-KO
09100	Metabolism	09101	Carbohydrate metabolism	hsa00010	Glycolysis / Gluconeogenesis	3101 HK3; hexokinase 3	K00844 HK; hexokinase [EC:2.7.1.1]
09100	Metabolism	09101	Carbohydrate metabolism	hsa00010	Glycolysis / Gluconeogenesis	3098 HK1; hexokinase 1	K00844 HK; hexokinase [EC:2.7.1.1]
...

#hsa_map.txt
hsa	Level-A	Level-B	Level-C
hsa04370	Environmental Information Processing	Signal transduction	VEGF signaling pathway
hsa00590	Metabolism	Lipid metabolism	Arachidonic acid metabolism
hsa00053	Metabolism	Carbohydrate metabolism	Ascorbate and aldarate metabolism
```

### 3.07 `KEGGPathwayCounter.py [3.06_生成文件_1] [GENE_KO]`
    
**Function Description:** KEGG pathway gene count statistics, exporting data for KEGG annotation enrichment plotting.

- **3.06_ Generated Files_1:** Generated files from script 3.06.
- **GENE_KO:** GENE-KO mapping table. The first column contains gene IDs or names, and the second column contains KO numbers (or other pathway IDs). Multiple KO numbers can be separated by commas. Please refer to the example file.  

**Generated File:** 
- A.txt (all_gene is the total number of genes, and you can use this number to find the gene ratio. TABLE file)  
- A-B.txt (TABLE file)   
- A-C.txt (TABLE file)   
- err.txt (There is no matching KO number. TABLE file)

**Example:**

For example, the files required in `example`: 
```
#Files generated by script 3.06: output_ko00001.txt
A-PATH	LEVEL-A	B-PATH	LEVEL-B	ID (C-PATH)	LEVEL-C	D-KO
09100	Metabolism	09101	Carbohydrate metabolism	ko00010	Glycolysis / Gluconeogenesis	K00844  HK; hexokinase [EC:2.7.1.1]
09100	Metabolism	09101	Carbohydrate metabolism	ko00010	Glycolysis / Gluconeogenesis	K12407  GCK; glucokinase [EC:2.7.1.2]
...

#Gene KO annotation result: gene_ko.txt
g03.1	ko04391,ko04392
g04.1	ko04142
g05.1	ko03022
g06.1	ko03320,ko04360,ko04510,ko05100,ko05131,ko05213
g08.1	ko04120
g13.1	ko05010
```
Execute the command: 
```bash
python KEGGPathwayCounter.py example/output_ko00001.txt example/gene_ko.txt
```
The result file will be generated: 
```
#A.txt
A	num
all_gene	6
Environmental Information Processing	1
Cellular Processes	2
Genetic Information Processing	2
Human Diseases	2
Organismal Systems	1

#A-B.txt
A	B	num
Environmental Information Processing	Signal transduction	1
Cellular Processes	Transport and catabolism	1
Genetic Information Processing	Transcription	1
Human Diseases	Infectious disease: bacterial	1
Organismal Systems	Endocrine system	1
Cellular Processes	Cellular community - eukaryotes	1
Human Diseases	Cancer: specific types	1
Organismal Systems	Development and regeneration	1
Genetic Information Processing	Folding, sorting and degradation	1
Human Diseases	Neurodegenerative disease	1

#A-C.txt
A	B	C	num
Environmental Information Processing	Signal transduction	Hippo signaling pathway - fly	1
Environmental Information Processing	Signal transduction	Hippo signaling pathway - multiple species	1
Cellular Processes	Transport and catabolism	Lysosome	1
Genetic Information Processing	Transcription	Basal transcription factors	1
Organismal Systems	Endocrine system	PPAR signaling pathway	1
Organismal Systems	Development and regeneration	Axon guidance	1
Cellular Processes	Cellular community - eukaryotes	Focal adhesion	1
Human Diseases	Infectious disease: bacterial	Bacterial invasion of epithelial cells	1
Human Diseases	Infectious disease: bacterial	Shigellosis	1
Human Diseases	Cancer: specific types	Endometrial cancer	1
Genetic Information Processing	Folding, sorting and degradation	Ubiquitin mediated proteolysis	1
Human Diseases	Neurodegenerative disease	Alzheimer disease	1

#err.txt
```

### 3.08 `GOoboAnnotationExtractor.py [obo_FILE]`

**Function Description:** Read and parse the descriptions and categories corresponding to GO terms from the obo file, generating a three-column table of GO ID \t description \t category. You can directly use the go_term_list.txt file provided in the example; however, please note that this file may not be the latest version. Therefore, it is recommended to use this script to extract the most up-to-date GO annotation information.

- **obo_FILE: ** The file path of the obo file downloaded from the GO website (open the URL: https://purl.obolibrary.org/obo/go/go-basic.obo. It is recommended to right-click on the webpage and select "Save As" to save it as a text file).

**Notes: ** Due to the possibility of incomplete webpage loading, it is not recommended to use CTRL+A to select all, CTRL+C to copy, then create a new text file and paste with CTRL+V.

**Generated File:** 
- `<version_number>_go_term_list.txt` (TABLE file; the first column is the GO ID, the second column is the description, and the third column is the category).

**Example:**

For example, if you have copied or saved the webpage content as abc.txt, you can run the code below: 
```bash
python GOoboAnnotationExtractor.py abc.txt
```
Because the file is updated in real-time, a current example file has not been provided.

### 3.09 `GOTableConverter.py [GENE_GOs_MAP]`
                 
**Function Description:** Convert GO annotation table:   
Convert the table:     
| Gene | GO Terms |          
| --- | --- |      
| GeneA | GO:000001, GO:000002 |      
| GeneB | GO:000006 |      

Convert to:      
| Gene | GO Term |            
| --- | --- |      
| GeneA	 | GO:000001 |      
| GeneA	 | GO:000002 |      
| GeneB	 | GO:000006 |    
  
where: the original table is not necessarily comma-separated; it can also be semicolon-separated or may contain redundant descriptive information, for example, in the format: GO:000001(description), GO:000002(description).

- **GENE_GOs_MAP: ** A two-column table, where the first column contains gene names and the second column contains multiple corresponding GO terms, with each row in a one-to-many format.

**Generated File:** 
- `g-go.txt` (TABLE file, the first column is geneid, the second column is GOID).     

**Example:**

For example, `example/seq_gos.txt` is the required file:
```
Accession_id	go
a0	"GO:0004176(molecular_function:ATP-dependent peptidase activity); GO:0004252(molecular_function:serine-type endopeptidase activity)"
a1	"GO:0043169(molecular_function:cation binding); GO:0004497(molecular_function:monooxygenase activity)"
a2	"GO:0001234; GO:GO:0004497"
```
Execute the command: 
```bash
python GOTableConverter.py example/seq_gos.txt
```
The result file will be generated:
```
a0	GO:0004176
a0	GO:0004252
a1	GO:0043169
a1	GO:0004497
a2	GO:0001234
a2	GO:0004497
```
      
### 3.10 `AddGOAnnotations.py [go_term_list] [GENE_GO_MAP]`
                 
**Function Description:** Add GO annotation descriptions and classification information to the gene-go file. The file generated by running this command will be used together with the R package clusterProfiler to perform enrichment analysis.

- **go_term_list:** It is recommended to use the `go_term_list.txt` file generated by script 3.08, which contains the descriptive information for all GO terms.  
- **GENE_GO_MAP:** It is recommended to use the file generated by script 3.09, with the first column being gene names and the second column being the corresponding GO IDs.

**Notes: ** Sometimes, your annotated table may have one column for gene IDs and another column containing multiple GO IDs. You can use script 3.09 (recommended) or the code below to convert a file where one gene corresponds to multiple GO IDs into a one-to-one format! If the GO IDs are separated by commas, simply change the semicolon in the code below to a comma—make sure to use English punctuation. `input_file` is your input filename, i.e., the table where one gene corresponds to multiple GO IDs, and `output_file` is the desired output filename; ensure it does not conflict with an existing file name.
```bash
awk -F'\t' '{split($2, arr, ";"); for (j in arr) print $1 "\t" arr[j]}' input_file > output_file
```
**Generated File:** 
- `gene_GO_info.txt` (TABLE file, the first column is geneid, the second column is GOID, the third column is the description, and the fourth column is the GO category classification).  

**Example:**

To use it, you need to generate a table file named xxx-go_term_list.txt using script 3.08. The example file 2024-01-17_go_term_list.txt corresponds to version 2024-01-17. It is recommended to obtain the latest version using script 3.08. File format:
```
#2024-01-17_go_term_list.txt
GO:0000001	mitochondrion inheritance	biological_process
GO:0000002	mitochondrial genome maintenance	biological_process
GO:0000003	reproduction	biological_process
GO:0019952	reproduction	biological_process
GO:0050876	reproduction	biological_process
GO:0000005	obsolete ribosomal chaperone activity	molecular_function
GO:0000006	high-affinity zinc transmembrane transporter activity	molecular_function
GO:0000007	low-affinity zinc ion transmembrane transporter activity	molecular_function
...

#gene_go.txt
gene1	GO:0000002
gene1	GO:0000003
gene1	GO:0000005
gene1	GO:0000006
gene2	GO:0000005
gene2	GO:0000007
```
Execute the command: 
```bash
python AddGOAnnotations.py example/2024-01-17_go_term_list.txt example/gene_go.txt
```
The result file will be generated: 
```
gene_id	ID	Description	ONTOLOGY
gene1	GO:0000002	mitochondrial genome maintenance	biological_process
gene1	GO:0000003	reproduction	biological_process
gene1	GO:0000005	obsolete ribosomal chaperone activity	molecular_function
gene1	GO:0000006	high-affinity zinc transmembrane transporter activity	molecular_function
gene2	GO:0000005	obsolete ribosomal chaperone activity	molecular_function
gene2	GO:0000007	low-affinity zinc ion transmembrane transporter activity	molecular_function
```

> ## GO/KEGG Enrichment Analysis Pipeline without a Reference Genome    
> When you have obtained the GO annotation results for all genes/proteins: ① If the original annotation table is in a one-to-many gene-GOs format, use script 3.09 to convert it into a one-to-one gene-GO format; ② Use script 3.08 to download and parse the description table for all GO terms; ③ Use script 3.10 to add GO annotation information for each gene; ④ Use the R package clusterProfiler to calculate GO term enrichment of a gene set of interest (e.g., differentially expressed genes, positively selected genes, expanded genes, etc.) against the background gene set (all annotated genes/proteins). Common enrichment metrics (used as the x-axis in bubble plots) include gene ratio, enrichment score (also known as fold enrichment), and rich factor. For example, if clusterProfiler outputs GeneRatio as 20/100 (indicating 20 out of 100 genes of interest are enriched in a specific term) and BgRatio as 50/150 (indicating 50 out of 150 total background genes are enriched in that term), then the gene ratio is 20/100 = 0.20, the enrichment score is the ratio of the two proportions: (20/100)/(50/150) = 0.6, and the rich factor is the ratio of the numerators: 20/50 = 0.4. Note that for model organisms such as mice and humans, the background gene set derived from your own annotations may be incomplete; therefore, it is recommended to use dedicated enrichment websites or toolkits.  
> The workflow for KEGG enrichment analysis without a reference genome is similar to that of GO enrichment analysis.  
> The R code for enrichment analysis is adapted from the "Reference-free GO Enrichment Analysis" section of the Zhihu article at https://zhuanlan.zhihu.com/p/561522453, with modifications to make it suitable for both KEGG and GO enrichment analysis.  
> **File 1: Background Gene Annotation Grouping File gene_ID.txt**  
> The first column contains gene or protein names (not necessarily unique); the second column contains GO IDs or KOs; the third column contains descriptive information—detailed explanations of GO terms (level2) for GO enrichment analysis, or levelC descriptions for KEGG analysis; the fourth column contains grouping information—GO's three main categories for GO analysis, or descriptions from levelA or levelB (to which levelC belongs) for KEGG analysis.  
> For GO enrichment analysis, this file can be generated using script 3.10, but must be modified to conform to the following format:             
> | gene_id | ID | Description | GROUP |            
> | --- | --- | --- | --- |        
> | GeneA | GO:000001 | mitochondrion inheritance | biological_process |        
> | GeneA | GO:000002 | mitochondrial genome maintenance | biological_process |         
> | GeneB | GO:000006 | high-affinity zinc transmembrane transporter activity | molecular_function |        
> | ... | ... | ... | ... |        

> The file for KEGG enrichment analysis needs to be modified according to the following format. This file can be generated using script 3.05 and Excel's VLOOKUP function:            
> | gene_id | ID | Description | GROUP |            
> | --- | --- | --- | --- |        
> | GeneA | ko00010 | Glycolysis / Gluconeogenesis | Metabolism |        
> | GeneA | ko00020 | Citrate cycle (TCA cycle) | Metabolism |         
> | GeneB | ko04016 | MAPK signaling pathway - plant | Environmental Information Processing |        
> | ... | ... | ... | ... |        

> **File 2: List of genes of interest (e.g., differentially expressed genes, specific genes, positively selected genes, etc.) gene.txt**  
> Must contain at least one column named "gene_id". Note that this column must not contain duplicate gene IDs, otherwise the calculation will be incorrect.       
> | gene_id |                   
> | --- |           
> | GeneA |     
> | GeneB |        
> | GeneD |         
> | ... |           

> Prepare the two files mentioned above, and then you can use the following code to calculate the enrichment statistics. Based on these statistics, you will be able to draw a bubble chart.       
> ```bash
> #The R code for enrichment analysis is adapted from the reference-free GO enrichment analysis section of the Zhihu article at https://zhuanlan.zhihu.com/p/561522453.      
> 
> library(clusterProfiler)        
> #Read the manually prepared background gene set
> gene_ID <- read.delim('gene_ID.txt', stringsAsFactors = FALSE)
> #Read the gene names from the gene list file
> genes <- read.delim('gene.txt', stringsAsFactors = FALSE)$gene_id
> #GO/KEGG Enrichment Analysis
> gene_rich <- enricher(gene = genes,  #List of genes to be enriched
>     TERM2GENE = gene_ID[c('ID', 'gene_id')],  #Background gene set
>     TERM2NAME = gene_ID[c('ID', 'Description')], 
>     pAdjustMethod = 'BH',  #Specify the p-value correction method
>     pvalueCutoff = 0.05,  #Specify the p-value threshold (set to 1 to output all results)
>     qvalueCutoff = 0.2)  #Specify the q-value threshold (set to 1 to output all results)
> #Output enrichment results
> write.table(gene_rich, 'gene_rich.txt', sep = '\t', row.names = FALSE, quote = FALSE)
> #Then add the GO Ontology or KEGG levelA information to the above enrichment results
> tmp <- read.delim('gene_rich.txt')
> gene_ID <- gene_ID[!duplicated(gene_GO$ID), ]
> tmp <- merge(tmp, gene_GO[c('ID', 'GROUP')], by = 'ID')
> tmp <- tmp[c(10, 1:9)]
> tmp <- tmp[order(tmp$pvalue), ]
> #Output
> write.table(tmp, 'gene_rich.add_Ontology.txt', sep = '\t', row.names = FALSE, quote = FALSE)
> ```       

### 3.11 `VectorTableMerger.py [A-Bs] [B-Cs] [s1（可选）] [s2（可选）]`
                 
**Function Description:** Join vector table:   
Convert the table:     
| GENE | CLA1 |          
| --- | --- |      
| G1 | A01;A02; A03 |      
| G2 | A02 |      
| G3 |   |      
| G4 | A04 |      
| G4 | A05 |   

and     
| CLA1 | CLA2 |          
| --- | --- |      
| A01 | B1;B2 |      
| A02 |   |      
| A03 | B1;B3 |      
| G05 | B4 |    

Merge into:     
| GENE | CLA2 |       
| --- | --- |     
| G1 | B3;B1;B2 |      
| G2 |   |      
| G3 |   |      
| G4 |   |      
| G4 | B4 |    

where: the original table requires a tab delimiter between the first and second columns; the delimiter for items in the second column is not necessarily ";", and can be specified as needed.

- **A-Bs:** Path to table one.  
- **B-Cs:** Path to table two.  
- **s1:** Delimiter for the items in the second column of table one.  
- **s2:** Delimiter for the items in the second column of table two.  

**Usage scenario:** When you have obtained gene annotation information in database X (including specific entry IDs or gene names), and you also know the corresponding IDs or names in database Y for each entry in database X, you can use this script to retrieve the corresponding names in database Y. You can think of this script as a variant of the VLOOKUP function, which is also suitable for deriving an A-C mapping from A-B and B-C mappings.      

**Notes: ** The parameters s1 and s2 must be specified simultaneously! It is recommended not to use a header row, as the final generated content may not have the header row in the expected position.       

**Generated File:** 
- `A-Cs.table` (TABLE file, the merged table).  
- `A-Cs_err.txt` (TABLE file, items that failed to match in the second table). 

**Example:**

For example, `example` contains two files: 
```
#A-Bs.txt
GENE	CLA1
G1	A01; A02; A03
G2	A02
G3	
G4	A04
G5	A05

#B-Cs.txt
CLA1	CLA2
A01	B1 ;B2
A02	
A03	B1;B3
A05	B4
```
Execute the command: 
```bash
#Do not specify the delimiter for the second column
python VectorTableMerger.py example/A-Bs.txt example/B-Cs.txt

#Specify the delimiter for the second column (specify according to the actual situation; semicolons are used in this example)
python VectorTableMerger.py example/A-Bs.txt example/B-Cs.txt ; ;
```
The result files will be generated: 
```
#A-Cs.table
GENE	CLA2
G1	B1;B3;B2
G2	
G3	
G4	
G5	B4

#A-Cs_err.txt
GENE	CLA1: not found!
G1	A01: not found!
G1	A03: not found!
G5	A05: not found!
```
  
## 4.Plotscript: Plotting script toolkit.     

### 4.01 `GeneArrangementMap.py [GENE_LIST] [COLOR_CONFIG] [Vertical_spacing]`
     
**Function Description:** To distinguish the linear arrangement of genes by different colors, you can use other more specialized tools for drawing.

- **GENE_LIST: ** List of gene sequences, TAB delimited. Each row represents a linear order of a genome. Different lines represent different genomes.
- **COLOR_CONFIG: ** Color configuration table, TAB delimited. The RGB hexadecimal representation of the colors in the first column and the gene names in the remaining columns.
- **Vertical_spacing: ** Spacing of adjacent row genomes, default 50.

**Notes: ** This script is provided for entertainment purposes only. It does not reflect the coding direction of features and simply concatenates basic circles and rectangles. It is suitable for combining with a phylogenetic tree after the tree has been constructed. A more visually appealing gene rearrangement visualization script will be developed in the future. This script will no longer be updated.

**Generated File:** 
- `out.svg` （SVG file）。

**Example:**

For example, `example` contains two files: 
```
#Gene arrangement file: gene.txt
F	12S	V	16S	L	ND1	I	Q	M	ND2	W	A	N	C	Y	COX1	S	D	COX2	K	ATP8	ATP6	COX3	G	ND3	R	ND4L	ND4	H	S	L	ND5	CYTB	T	P	ND6	E	D-loop
F	12S	V	16S	L	ND1	I	Q	M	ND2	W	A	N	C	Y	COX1	S	D	COX2	K	ATP8	ATP6	COX3	G	ND3	R	ND4L	ND4	H	S	L	ND5	CYTB	T	P	ND6	E	D-loop
F	12S	V	16S	L	ND1	I	Q	M	ND2	W	A	N	C	Y	COX1	S	D	COX2	K	ATP8	ATP6	COX3	G	ND3	R	ND4L	ND4	H	S	L	ND5	CYTB	T	P	ND6	E	D-loop
...

#Feature fill color: color.txt
#FFD966	F	V	L	I	Q	M	W	A	N	C	Y	S	D	K	G	R	H	S	L	T	P	E
#DDEBF7	12S	16S																				
#FFFF00	ND1	ND2	ND3	ND4L	ND4	ND5	ND6															
#FCE4D6	 COX1	 COX2	 COX3																			
#70AD47	ATP8	ATP6																				
#2F75B5	CYTB																					
#E7E6E6	D-loop	
```
Execute the command: 
```bash 
python GeneArrangementMap.py example/gene.txt example/color.txt 50
```
An SVG file will be generated, which can be opened directly with a web browser.

### 4.02 `TrnaStructureBeautifier.py [-h] -i INPUT [-s SIZE_WEIGHT] [-p PER_ROW] [-hg HORIZONTAL_GAP] [-vg VERTICAL_GAP] [-ac ADJACENT_COLOR] [-pc PAIR_COLOR] [-bf BASE_FILL] [-bs BASE_STROKE] [-A BASE_A] [-U BASE_U] [-G BASE_G] [-C BASE_C]`
         
**Function Description:** To beautify the tRNA secondary structure drawn using the RNAplot function of the ViennaRNA package, annotations like those from MitoS are very suitable for use with this script.

**Parameter Description:** 

```bash
options:
  -h, --help            show this help message and exit
  -i, --input INPUT     Path to the SVG file or the directory containing SVG files
  -s, --size-weight SIZE_WEIGHT
                        Scaling factor for the graphic (default 1.4)
  -p, --per-row PER_ROW
                        Number of images per row (default 4)
  -hg, --horizontal-gap HORIZONTAL_GAP
                        Horizontal gap between images (default 8)
  -vg, --vertical-gap VERTICAL_GAP
                        Vertical gap between images (default 5)
  -ac, --adjacent-color ADJACENT_COLOR
                        Color for lines connecting adjacent bases (supports color names or HEX values, e.g., "blue" or "#00FF00", default "blue")
  -pc, --pair-color PAIR_COLOR
                        Color for lines connecting paired bases (supports color names or HEX values, e.g., "red" or "#FF0000", default "red")
  -bf, --base-fill BASE_FILL
                        Fill color for base circles (default "white")
  -bs, --base-stroke BASE_STROKE
                        Stroke (outline) color for base circles (default "black")
  -A, --base-a BASE_A   Fill color for adenine (A) base circles (default "red")
  -U, --base-u BASE_U   Fill color for uracil/thymine (U/T) base circles (default "blue")
  -G, --base-g BASE_G   Fill color for guanine (G) base circles (default "green")
  -C, --base-c BASE_C   Fill color for cytosine (C) base circles (default "yellow")      
```

**Usage scenario:** You have obtained a preliminary SVG version of the tRNA secondary structure and need to enhance its appearance and merge multiple images.

**Notes: ** 

① The script uses the text before the first "-" as the RNA name (if not present, it uses the file name). Adjust the file naming format accordingly before running the script.  
② This script is only suitable for beautifying secondary structure diagrams generated by RNAplot (e.g., from software like Mitoos).  
③ The `-i` parameter is required and can point to either a single SVG file or a folder containing multiple SVG files. All other parameters have default values and can be adjusted based on the output results.  
④ If text overlapping occurs in the output, adjust the spacing between images or the scaling factor. For fine-tuning, we recommend editing the SVG files using software such as Adobe Illustrator.  
⑤ If `-i` specifies a folder, the folder may contain other files or subfolders, but must not contain any additional SVG files. For example, if using Mitoos-generated plots, the "plot" folder might also include rRNA secondary structures—these should be removed beforehand.  
⑥ If you need to run the script again, it's recommended to clear or delete the existing "modified" folder. Although re-running will overwrite previous results, it may otherwise leave behind unexpected extra files. 

**Video tutorial:** https://www.bilibili.com/video/BV1FzbRzjERa/  

**Generated File:** 
- `modified`(folder: ① modified_X.svg files are beautified individual secondary structures, corresponding one-to-one with the original files, where "X" is the part before the first "-" in the original filename; ② group_X.svg files are combined images arranged in rows; ③ final.svg is the combined image without colored bases, which is personally preferred; ④ final_color.svg is the version with colored bases.)

**Example:**

In the folder, `example/mitos_RNA_plot` contains all the tRNA secondary structure diagrams, while `example/trnG.svg` is an individual diagram. 
```bash
# Use default parameters to beautify the images
python TrnaStructureBeautifier.py -i example/mitos_RNA_plot #Specify a folder  
python TrnaStructureBeautifier.py -i example/trnG.svg #Specify a file  

# Use all configuration parameters
python TrnaStructureBeautifier.py -i example/mitos_RNA_plot -s 1.8 -p 6 -hg 12 -vg 7 -ac "red" -pc "#FF0000" -bf "#FFFF00" -bs "#000000" -A "#FF0000" -U "#0000FF" -G "#00FF00" -C "#FFFF00" 
```
Results will be generated in the output folder. Note that if you notice missing tRNAs in the combined image, please do not be alarmed—try opening the image in a browser and zooming out with the scroll wheel to see the complete picture!  

## 5.BioDataSpider: Biological database web crawler tool module.  

### 5.01 `GenoSpider`

**Function Description:** Genome data crawler; detailed explanation can be found in the master's thesis!  

**Parameter Description:** 

```bash
#The tool offers two execution modes: interactive mode and command-line mode. The command-line mode supports only streamlined input and output for a single category, while the interactive mode provides more personalized operation options.

#Command-line mode
python GenoSpider.py [-h] [-s] [-f {jpg,png,svg,eps}] [-p PIXELS] [-r] [-u] [-w WIDTH] [-H HEIGHT] [-g GAP] [-n NAME] [-i TID] [-l LEVEL]

## Running "python GenoSpider.py -n Aves -u -r -l superorder" will retrieve all reference genome information for the class Aves.

## GenoSpider.py -h=[show help message] -s=[simplify assembly information table, boolean flag, default: False]  
## -f=[output image format, choose one from jpg, png, svg, eps; default: jpg]  
## -p=[output image resolution in dpi, default: 300] -r=[output reference genomes only, boolean flag, default: False]  
## -u=[offline mode, boolean flag, default: False] -l=[taxonomic rank to be summarized in the output image]  
## -w=[image width in inches, default: 8] -H=[image height in inches, default: 10] -g=[subplot spacing, default: 0.4]  
## -n=[scientific (Latin) name, specify either this or -i] -i=[species ID, specify either this or -n]

#Interactive mode
python GenoSpider.py

##Run "python GenoSpider.py" without parameters to launch the interactive mode. Once in interactive mode, you can enter the corresponding function number or function name in the panel to execute the desired operation.

>> Function Number    Function Name    Corresponding Operation
>> 1    getTaxInfoFromName      Get taxonomic information for Scientific name of species.
>> 2    getTaxInfoFromNameList  Get taxonomic information for all species in a list.
>> 3    getTaxInfoFromTid       Get taxonomic information for Tax ID of species.
>> 4    getTaxInfoFromTidList   Get taxonomic information for Tax ID in a list.
>> 5    getAssembleFromName     Get information about all genomes in a given category. It is not recommended due to the occurrence of species with the same name.
>> 6    getAssembleFromTid      Get information about all genomes in a given Tax ID.
>> 7    getAssembleFromTidList  Get information about all genomes in a given Tax ID in a list.
>> 8    getTaxInfoFromAssemble  The taxonomic information is obtained from the assembly information file. This is equivalent to the getTaxInfoFromTidList being triggered automatically after manually executing the command to get the assembly information.
>> 9    mergeAssemble_TaxInfo   Merge assembly information and species classification information files.
>> p    dataVisualization       Output visual image.
>> c    com     Output a list of all functions.
>> h    help    Get complete help information.
>> f    settingOutputFormat     View or configure the output format.
>> e    exit    exit the program.
```

**Notes: ** You need to install the requests, pandas, and matplotlib libraries!  

### 5.02 `PrideSpider.py [SP_LIST]`   

**Function Description:** A crawler designed to retrieve information from the PRIDE database!  

- **SP_LIST: ** Species scientific (Latin) name / common name, with each line representing one species.

**Notes: ** Currently, batch downloading of results in JSON format is supported. Functionality for parsing JSON files will be added in future updates.  

**Generated File:** 
- `log.txt` (log file, which shows how many data entries exist for each species' scientific/common name; if network issues occur, you can check which species have already been processed to avoid duplicate data requests)  
- `json_result` (folder containing the crawled information in JSON format, with filenames named in the format "scientific_name-page_number")   

**Example:**

In the folder, `example/sp.txt` contains the scientific names of several species: 
```
Acipenser ruthenus
Danio rerio
Leucoraja erinaceus
```
Execute the command: 
```bash
python PrideSpider.py example/sp.txt
```
You can then download all the content. The crawled data is in JSON format, which you can either parse using a script written with the help of AI, or directly integrate into your web page.




==============      
**Author: Hao Xue**     
**E-mail: studid@163.com**   
**Citation: There is no publication to cite. If this tool has been helpful to your research, just secretly think I'm awesome!**   
You may consider adding the following:  
In Chinese publications: "我们使用了 BioDataTools 工具 (https://github.com/shueho/BioDataTools) 进行XXX分析"  
In English publications: "We used BioDataTools (https://github.com/shueho/BioDataTools) for XXX analysis."  
When citing in a thesis:
[1] Xue, H. (2024). Genome Structure and Comparative Genomic Analysis of Alectoris magna. Yantai University, Yantai.
        
<a href="https://orcid.org/0000-0001-9708-3575" target="_blank" rel="noopener noreferrer me">
  <img src="https://orcid.org/sites/default/files/images/orcid_16x16.png" alt="ORCID iD icon" style="width: 1em; margin-inline-start: 0.5em" />
  https://orcid.org/0000-0001-9708-3575
</a>

